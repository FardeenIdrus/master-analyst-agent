"""
#version 2
LLM Agent Module - AI-Powered Trading Analysis

Advanced Claude API integration for intelligent trade analysis:
1. Structured Outputs: Pydantic models for guaranteed JSON format
2. Tool-Calling: Dynamic data requests for deeper analysis
3. Chain-of-Thought: Step-by-step reasoning transparency
4. Multi-Stage Analysis: Technical -> Regime -> Risk -> Recommendation

Outputs professional trade notes with:
- Executive summary (BUY/SELL/HOLD with confidence)
- Technical analysis section
- Regime context
- Risk factors
- Trade specifications
- Performance attribution
"""

import os
import json
import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
from datetime import datetime
import warnings

# Try to import Anthropic SDK
try:
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    warnings.warn("Anthropic SDK not installed. Install with: pip install anthropic")

# Try to import OpenAI as fallback
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from dotenv import load_dotenv
from pathlib import Path

# Load environment variables from repo root .env file
# Go up from src/ -> fardeen_technical_agent/ -> technical_agents/ -> master-analyst-agent/
repo_root = Path(__file__).parent.parent.parent.parent
load_dotenv(repo_root / ".env")


# =============================================================================
# ENUMS AND DATA CLASSES
# =============================================================================

class Recommendation(Enum):
    """Trading recommendation types."""
    STRONG_BUY = "STRONG_BUY"
    BUY = "BUY"
    HOLD = "HOLD"
    SELL = "SELL"
    STRONG_SELL = "STRONG_SELL"


class RiskLevel(Enum):
    """Risk assessment levels."""
    LOW = "LOW"
    MODERATE = "MODERATE"
    HIGH = "HIGH"
    EXTREME = "EXTREME"


@dataclass
class TradeRecommendation:
    """Structured trade recommendation from LLM."""
    recommendation: Recommendation
    confidence: float  # 0-1 scale
    rationale: str
    entry_price: float
    stop_loss: float
    take_profit: float
    position_size_pct: float
    risk_reward_ratio: float
    risks: List[str]
    catalysts: List[str]
    time_horizon: str  # "intraday", "swing", "position"

    # New fields for enhanced analysis
    technical_analysis_summary: str = ""
    target_1: Optional[float] = None
    target_2: Optional[float] = None
    target_3: Optional[float] = None
    scenarios: Optional[Dict[str, Any]] = None
    investment_thesis: str = ""
    support_levels: Optional[List[float]] = None
    resistance_levels: Optional[List[float]] = None

    # Performance analysis (merged from analyse_performance)
    performance_analysis: Optional[Dict[str, Any]] = None

    # Enhanced analysis fields (v2)
    rationale_breakdown: Optional[Dict[str, Any]] = None
    timeframe_analysis: Optional[Dict[str, Any]] = None
    stop_loss_reasoning: str = ""
    target_1_reasoning: str = ""
    target_2_reasoning: str = ""
    target_3_reasoning: str = ""
    confidence_breakdown: Optional[Dict[str, Any]] = None
    chart_patterns: Optional[Dict[str, Any]] = None
    invalidation_conditions: Optional[List[str]] = None

    def to_dict(self) -> Dict[str, Any]:
        result = {
            'recommendation': self.recommendation.value,
            'confidence': self.confidence,
            'rationale': self.rationale,
            'entry_price': self.entry_price,
            'stop_loss': self.stop_loss,
            'take_profit': self.take_profit,
            'position_size_pct': self.position_size_pct,
            'risk_reward_ratio': self.risk_reward_ratio,
            'risks': self.risks,
            'catalysts': self.catalysts,
            'time_horizon': self.time_horizon,
            'technical_analysis_summary': self.technical_analysis_summary,
            'investment_thesis': self.investment_thesis
        }
        if self.target_1 is not None:
            result['target_1'] = self.target_1
            result['target_2'] = self.target_2
            result['target_3'] = self.target_3
        if self.scenarios is not None:
            result['scenarios'] = self.scenarios
        if self.support_levels:
            result['support_levels'] = self.support_levels
        if self.resistance_levels:
            result['resistance_levels'] = self.resistance_levels
        if self.performance_analysis:
            result['performance_analysis'] = self.performance_analysis
        if self.rationale_breakdown:
            result['rationale_breakdown'] = self.rationale_breakdown
        if self.timeframe_analysis:
            result['timeframe_analysis'] = self.timeframe_analysis
        if self.stop_loss_reasoning:
            result['stop_loss_reasoning'] = self.stop_loss_reasoning
        if self.target_1_reasoning:
            result['target_1_reasoning'] = self.target_1_reasoning
            result['target_2_reasoning'] = self.target_2_reasoning
            result['target_3_reasoning'] = self.target_3_reasoning
        if self.confidence_breakdown:
            result['confidence_breakdown'] = self.confidence_breakdown
        if self.chart_patterns:
            result['chart_patterns'] = self.chart_patterns
        if self.invalidation_conditions:
            result['invalidation_conditions'] = self.invalidation_conditions
        return result


@dataclass
class PerformanceAnalysis:
    """Structured performance analysis from LLM."""
    summary: str
    strengths: List[str]
    weaknesses: List[str]
    attribution: Dict[str, str]  # Factor -> explanation
    warnings: List[str]
    suggestions: List[str]
    overall_assessment: str  # "excellent", "good", "fair", "poor"
    confidence_in_edge: float  # 0-1, confidence strategy has real edge

    def to_dict(self) -> Dict[str, Any]:
        return {
            'summary': self.summary,
            'strengths': self.strengths,
            'weaknesses': self.weaknesses,
            'attribution': self.attribution,
            'warnings': self.warnings,
            'suggestions': self.suggestions,
            'overall_assessment': self.overall_assessment,
            'confidence_in_edge': self.confidence_in_edge
        }


@dataclass
class AnalysisContext:
    """Context data for LLM analysis."""
    ticker: str
    current_price: float
    current_date: str

    # Technical indicators
    rsi: float
    macd: float
    macd_signal: float
    sma_50: float
    sma_200: float
    bb_percent_b: float
    atr: float
    adx: float

    # Regime information
    market_regime: str
    volatility_regime: str
    trend_persistence: str
    hurst_exponent: float
    regime_confidence: float

    # Signal information
    signal: str
    signal_confidence: float
    confluence_score: float
    strategy: str

    # === BASIC PERFORMANCE METRICS ===
    total_return: Optional[float] = None
    cagr: Optional[float] = None
    volatility: Optional[float] = None
    sharpe_ratio: Optional[float] = None
    max_drawdown: Optional[float] = None

    # === ADVANCED RISK-ADJUSTED METRICS ===
    sortino_ratio: Optional[float] = None
    calmar_ratio: Optional[float] = None
    omega_ratio: Optional[float] = None
    profit_factor: Optional[float] = None

    # === RISK METRICS (VaR/CVaR) ===
    var_95: Optional[float] = None
    var_99: Optional[float] = None
    cvar_95: Optional[float] = None
    cvar_975: Optional[float] = None

    # === PROBABILISTIC METRICS ===
    probabilistic_sharpe: Optional[float] = None
    deflated_sharpe: Optional[float] = None
    sharpe_ci_lower: Optional[float] = None
    sharpe_ci_upper: Optional[float] = None

    # === TRADE STATISTICS ===
    total_trades: Optional[int] = None
    win_rate: Optional[float] = None
    avg_win: Optional[float] = None
    avg_loss: Optional[float] = None
    best_trade: Optional[float] = None
    worst_trade: Optional[float] = None
    avg_trade_duration: Optional[float] = None

    # === STATISTICAL TESTS ===
    cagr_tstat: Optional[float] = None
    cagr_pvalue: Optional[float] = None
    returns_skewness: Optional[float] = None
    returns_kurtosis: Optional[float] = None
    jarque_bera_stat: Optional[float] = None
    jarque_bera_pvalue: Optional[float] = None

    # === MONTE CARLO RESULTS ===
    mc_cagr_percentile: Optional[float] = None
    mc_is_significant: Optional[bool] = None
    mc_prob_loss: Optional[float] = None
    mc_cagr_5th: Optional[float] = None
    mc_cagr_25th: Optional[float] = None
    mc_cagr_50th: Optional[float] = None
    mc_cagr_75th: Optional[float] = None
    mc_cagr_95th: Optional[float] = None
    mc_sharpe_median: Optional[float] = None
    mc_max_dd_median: Optional[float] = None

    # === POSITION SIZING (from PositionSizer) ===
    full_kelly: Optional[float] = None  # Full Kelly fraction from trade stats
    fractional_kelly: Optional[float] = None  # Kelly Ã— fraction multiplier (e.g., quarter-Kelly)
    kelly_multiplier: Optional[float] = None  # The fraction used (e.g., 0.25 for quarter-Kelly)
    garch_volatility: Optional[float] = None
    vol_adjusted_size: Optional[float] = None

    # === TIME PERIOD ===
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    trading_days: Optional[int] = None
    years: Optional[float] = None

    # === COMPONENT SCORES (0-100 scale) ===
    momentum_score: Optional[float] = None
    trend_score: Optional[float] = None
    volatility_score: Optional[float] = None
    volume_score: Optional[float] = None
    overall_score: Optional[float] = None

    # === ADDITIONAL TECHNICAL LEVELS ===
    bb_upper: Optional[float] = None
    bb_lower: Optional[float] = None
    bb_middle: Optional[float] = None
    volume_ratio: Optional[float] = None  # Current volume / average volume

    # === MULTI-TARGET LEVELS ===
    target_1: Optional[float] = None  # Conservative target
    target_2: Optional[float] = None  # Base case target
    target_3: Optional[float] = None  # Aggressive target

    def to_dict(self) -> Dict[str, Any]:
        return {k: v for k, v in self.__dict__.items() if v is not None}


# =============================================================================
# TOOL DEFINITIONS FOR LLM
# =============================================================================

AVAILABLE_TOOLS = [
    {
        "name": "fetch_indicator_history",
        "description": "Fetch historical values for a specific technical indicator",
        "input_schema": {
            "type": "object",
            "properties": {
                "indicator": {
                    "type": "string",
                    "description": "Indicator name (RSI, MACD, SMA_50, etc.)"
                },
                "periods": {
                    "type": "integer",
                    "description": "Number of periods to fetch"
                }
            },
            "required": ["indicator", "periods"]
        }
    },
    {
        "name": "calculate_correlation",
        "description": "Calculate correlation between the asset and a benchmark",
        "input_schema": {
            "type": "object",
            "properties": {
                "benchmark": {
                    "type": "string",
                    "description": "Benchmark ticker (SPY, QQQ, etc.)"
                },
                "periods": {
                    "type": "integer",
                    "description": "Number of periods for correlation"
                }
            },
            "required": ["benchmark", "periods"]
        }
    },
    {
        "name": "get_regime_history",
        "description": "Get historical regime classifications",
        "input_schema": {
            "type": "object",
            "properties": {
                "periods": {
                    "type": "integer",
                    "description": "Number of periods to fetch"
                }
            },
            "required": ["periods"]
        }
    },
    {
        "name": "get_recent_trades",
        "description": "Get recent trade history with P&L",
        "input_schema": {
            "type": "object",
            "properties": {
                "count": {
                    "type": "integer",
                    "description": "Number of recent trades to fetch"
                }
            },
            "required": ["count"]
        }
    }
]


# =============================================================================
# LLM AGENT CLASS
# =============================================================================

class LLMAgent:
    """
    AI-powered trading analysis agent using Claude API.

    Features:
    - Structured outputs with Pydantic-style validation
    - Tool calling for dynamic data retrieval
    - Chain-of-thought reasoning
    - Multi-stage analysis pipeline

    Usage:
        agent = LLMAgent(data_df)
        recommendation = agent.generate_trade_recommendation(context)
        analysis = agent.analyse_performance(metrics, mc_results)
        report = agent.generate_full_report(context, metrics)
    """

    # Single unified prompt for complete analysis (trade + performance in one API call)
    TRADE_ANALYSIS_PROMPT = """You are a senior quantitative analyst at Goldman Sachs Asset Management writing an institutional trade note.

CRITICAL CONSTRAINT:
The quantitative signal system has already generated a recommendation: {signal}
with confluence score: {confluence:.2f} and confidence: {confidence:.0%}.
You MUST use this signal as your final recommendation. Do NOT override it.
Your role is to EXPLAIN and VALIDATE this decision with institutional-quality analysis.

ANALYSIS FRAMEWORK:

1. Technical Indicator Analysis
   - RSI: Is it overbought (>70), oversold (<30), or neutral? How does this support the {signal}?
   - MACD: Is the histogram positive/negative? Is there a crossover? Any divergence with price?
   - Moving Averages: Is price above/below SMA 50 and SMA 200? Golden/Death cross forming?
   - ADX: Is the trend strong (>25) or weak (<20)? What does this mean for the signal?
   - Bollinger Bands: Is price near upper/lower band? Is a squeeze forming?
   - Volume: Is volume confirming the price action or showing divergence?

2. Regime Context
   - Market Regime: How does the current regime (bull/bear/sideways) affect the signal?
   - Volatility Regime: Is volatility high or low? How should this impact position sizing?
   - Trend Persistence (Hurst): Is the market trending (H>0.5) or mean-reverting (H<0.5)?
   - Explain specifically why the {signal} signal is appropriate for this regime

3. Confluence Analysis
   - List which indicators are currently bullish vs bearish
   - Explain how the confluence score of {confluence:.2f} was derived
   - Identify any conflicting signals and explain why they were outweighed

4. Risk Assessment
   - Identify 3-5 specific risks that could invalidate this signal
   - Format each risk as: "[Risk description]; mitigation through [specific action]"
   - Key support/resistance levels to watch
   - What price action would cause an early exit?

5. Catalysts (COMPANY-SPECIFIC - DO NOT USE GENERIC CATALYSTS)
   - Identify 2-3 SPECIFIC upcoming bullish catalysts for THIS company
     Examples: "Q2 earnings on July 25", "iPhone 16 launch September", "WWDC announcements June 10"
   - Identify 2 SPECIFIC bearish catalysts or headwinds for THIS company
     Examples: "EU DMA compliance deadline March 7", "DOJ antitrust trial ruling expected Q2"
   - DO NOT use generic catalysts like "positive earnings" or "new product launch"
   - Reference specific dates, events, or known business developments

6. Trade Specification (required for BUY/SELL, optional for HOLD)
   - Entry price with reasoning (explain WHY this level - e.g., "at current price near SMA support")
   - Stop loss level with specific reasoning (e.g., "2x ATR below entry" or "below swing low at $X")
   - Three take profit targets with reasoning for each:
     * T1 (conservative): Based on what technical level?
     * T2 (base case): Based on what technical level?
     * T3 (aggressive): Based on what technical level?
   - Position size recommendation based on current volatility regime
   - Risk/reward ratio

7. Scenario Analysis (WITH PROBABILITIES)
   - Bull case (20-40% probability): Target price, % return, key drivers
   - Base case (40-50% probability): Target price, % return, key drivers
   - Bear case (20-35% probability): Target price, % return (negative), key drivers
   - Calculate expected value: weighted average of scenario returns

8. Investment Thesis (3-4 PARAGRAPHS - THIS IS CRITICAL)
   Write a detailed, institutional-quality investment thesis that includes:

   PARAGRAPH 1 - PRIMARY SETUP: Describe the core technical setup driving this {signal}.
   What is the dominant pattern or condition? Why does it matter at current levels?
   Reference specific indicator values (e.g., "RSI at 55 with positive divergence").

   PARAGRAPH 2 - SIGNAL CONFLUENCE: Detail which indicators agree vs disagree.
   Explain the weight of evidence - why do the confirming signals outweigh conflicts?
   Be specific: "4 of 6 momentum indicators are bullish while 2 show neutral readings."

   PARAGRAPH 3 - HISTORICAL CONTEXT: Have we seen similar setups before?
   What typically happens in this regime with these indicator readings?
   Reference the backtest win rate and historical patterns if available.

   PARAGRAPH 4 - EXECUTION GUIDANCE: What would change this recommendation?
   Specify exact price levels or indicator readings that would invalidate the thesis.
   What should the trader monitor most closely?

9. Strategy Performance Assessment (if backtest metrics provided)
   - Evaluate CAGR vs benchmarks (S&P ~10% annually)
   - Assess Sharpe ratio quality (>1 good, >2 excellent)
   - Review Monte Carlo percentile (>60th suggests real edge vs luck)
   - Identify strategy strengths and weaknesses
   - Provide confidence in edge (is this skill or luck?)

CHAIN OF THOUGHT:
Provide detailed reasoning in your rationale, not just conclusions.

OUTPUT FORMAT:
Provide your analysis in this exact JSON structure:
{{
    "recommendation": "{signal}",
    "confidence": {confidence},
    "rationale": "Comprehensive 4-6 sentence explanation covering: (1) why the signal was generated, (2) key supporting indicators, (3) regime context, (4) any conflicts and why they were outweighed",
    "rationale_breakdown": {{
        "primary_drivers": ["indicator 1 with value", "indicator 2 with value"],
        "confirming_signals": ["signal 1", "signal 2"],
        "conflicting_signals": ["conflict 1 and why outweighed", "conflict 2 and why outweighed"],
        "decision_logic": "One sentence explaining the final weighing of evidence"
    }},
    "technical_analysis_summary": "4-6 sentence institutional-quality narrative explaining the complete technical picture.",
    "timeframe_analysis": {{
        "primary_timeframe": "daily",
        "trend_daily": "bullish|bearish|neutral",
        "trend_weekly": "bullish|bearish|neutral",
        "timeframe_alignment": "aligned|mixed|conflicting"
    }},
    "entry_price": float,
    "stop_loss": float,
    "stop_loss_reasoning": "Explain why this stop level (e.g., '2x ATR below entry' or 'below key swing low')",
    "take_profit": float,
    "target_1": float,
    "target_1_reasoning": "Why this level (e.g., 'SMA 50 resistance')",
    "target_2": float,
    "target_2_reasoning": "Why this level (e.g., 'Previous swing high')",
    "target_3": float,
    "target_3_reasoning": "Why this level (e.g., 'Fibonacci 161.8% extension')",
    "position_size_pct": 0.0-1.0,
    "risk_reward_ratio": float,
    "risks": ["Risk 1 with trigger; mitigation through X", "Risk 2 with trigger; mitigation through Y", "Risk 3", "Risk 4"],
    "catalysts": ["SPECIFIC bullish catalyst for THIS ticker (e.g., 'Upcoming iPhone 16 launch in September')", "Another SPECIFIC bullish catalyst", "SPECIFIC bearish catalyst for THIS ticker (e.g., 'DOJ antitrust ruling expected Q2')", "Another SPECIFIC bearish catalyst"],
    "time_horizon": "intraday|swing|position",
    "support_levels": [nearest_support_price, secondary_support_price],
    "resistance_levels": [nearest_resistance_price, secondary_resistance_price],
    "confidence_breakdown": {{
        "base_score": 50,
        "momentum_contribution": float (-20 to +20),
        "trend_contribution": float (-20 to +20),
        "regime_contribution": float (-20 to +20),
        "volume_contribution": float (-10 to +10),
        "interpretation": "Explain why confidence is high/medium/low"
    }},
    "chart_patterns": {{
        "detected": ["pattern 1", "pattern 2"],
        "forming": ["potential pattern"],
        "pattern_implication": "What these patterns suggest for price action"
    }},
    "scenarios": {{
        "bull_case": {{
            "probability": 0.25-0.35,
            "target_price": float,
            "return_pct": float,
            "drivers": ["driver 1", "driver 2"]
        }},
        "base_case": {{
            "probability": 0.40-0.50,
            "target_price": float,
            "return_pct": float,
            "drivers": ["driver 1", "driver 2"]
        }},
        "bear_case": {{
            "probability": 0.20-0.30,
            "target_price": float,
            "return_pct": float,
            "drivers": ["driver 1", "driver 2"]
        }},
        "expected_value_pct": float
    }},
    "investment_thesis": "FULL 3-4 PARAGRAPH thesis as described above. This must be detailed and institutional-quality, not just 2-3 sentences.",
    "invalidation_conditions": ["Specific condition 1 that would invalidate thesis", "Condition 2", "Condition 3"],
    "performance_analysis": {{
        "summary": "One paragraph assessment of strategy quality based on backtest metrics",
        "overall_assessment": "excellent|good|fair|poor",
        "confidence_in_edge": 0.0-1.0,
        "strengths": ["strength 1", "strength 2"],
        "weaknesses": ["weakness 1", "weakness 2"],
        "warnings": ["warning if any"],
        "suggestions": ["improvement suggestion if any"]
    }}
}}"""

    def __init__(
        self,
        data: Optional[pd.DataFrame] = None,
        model: str = "claude-sonnet-4-20250514",
        fallback_model: str = "gpt-4o",
        max_tokens: int = 4096,
        temperature: float = 0.3
    ):
        """
        Initialise LLM agent.

        Args:
            data: DataFrame with price and indicator data (for tool calls)
            model: Claude model to use
            fallback_model: OpenAI model if Claude unavailable
            max_tokens: Maximum response tokens
            temperature: Sampling temperature (lower = more deterministic)
        """
        
        self.data = data
        self.model = model
        self.fallback_model = fallback_model
        self.max_tokens = max_tokens
        self.temperature = temperature

        # Initialise API clients
        self.anthropic_client = None
        self.openai_client = None

        # Try Anthropic first
        if ANTHROPIC_AVAILABLE:
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if api_key:
                self.anthropic_client = Anthropic(api_key=api_key)
                print(" LLM Agent initialised with Claude API")
            else:
                warnings.warn("ANTHROPIC_API_KEY not found in environment")

        # Fallback to OpenAI
        if self.anthropic_client is None and OPENAI_AVAILABLE:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.openai_client = OpenAI(api_key=api_key)
                print(" LLM Agent initialised with OpenAI API (fallback)")
            else:
                warnings.warn("OPENAI_API_KEY not found in environment")

        if self.anthropic_client is None and self.openai_client is None:
            warnings.warn("No LLM API available. Analysis will return placeholder results.")

        # Tool handlers
        self.tool_handlers: Dict[str, Callable] = {
            'fetch_indicator_history': self._fetch_indicator_history,
            'calculate_correlation': self._calculate_correlation,
            'get_regime_history': self._get_regime_history,
            'get_recent_trades': self._get_recent_trades
        }

        # Trade history (can be set externally)
        self.trades_df: Optional[pd.DataFrame] = None

    # =========================================================================
    # TOOL IMPLEMENTATIONS
    # =========================================================================

    def _fetch_indicator_history(self, indicator: str, periods: int) -> Dict[str, Any]:
        """Fetch historical indicator values."""
        if self.data is None or indicator not in self.data.columns:
            return {"error": f"Indicator {indicator} not available"}

        values = self.data[indicator].tail(periods).tolist()
        dates = self.data.index[-periods:].strftime('%Y-%m-%d').tolist()

        return {
            "indicator": indicator,
            "periods": periods,
            "values": values,
            "dates": dates,
            "current": values[-1] if values else None,
            "mean": np.mean(values) if values else None,
            "std": np.std(values) if values else None
        }

    def _calculate_correlation(self, benchmark: str, periods: int) -> Dict[str, Any]:
        """Calculate correlation with benchmark."""
        if self.data is None:
            return {"error": "No data available"}

        # For now, return placeholder - would need benchmark data
        returns = self.data['Close'].pct_change().tail(periods)

        return {
            "benchmark": benchmark,
            "periods": periods,
            "correlation": 0.7,  # Placeholder
            "note": "Benchmark data not loaded - showing placeholder"
        }

    def _get_regime_history(self, periods: int) -> Dict[str, Any]:
        """Get regime classification history."""
        if self.data is None or 'Market_Regime' not in self.data.columns:
            return {"error": "Regime data not available"}

        regimes = self.data['Market_Regime'].tail(periods).tolist()
        dates = self.data.index[-periods:].strftime('%Y-%m-%d').tolist()

        # Count regime distribution
        from collections import Counter
        distribution = dict(Counter(regimes))

        return {
            "periods": periods,
            "regimes": regimes,
            "dates": dates,
            "distribution": distribution,
            "current": regimes[-1] if regimes else None
        }

    def _get_recent_trades(self, count: int) -> Dict[str, Any]:
        """Get recent trade history."""
        if self.trades_df is None or len(self.trades_df) == 0:
            return {"error": "No trade history available"}

        recent = self.trades_df.tail(count)

        trades_list = []
        for _, row in recent.iterrows():
            trade = {
                'return': float(row.get('Return', 0)),
                'pnl': float(row.get('PnL', 0)) if 'PnL' in row else None
            }
            trades_list.append(trade)

        return {
            "count": len(trades_list),
            "trades": trades_list,
            "win_rate": sum(1 for t in trades_list if t['return'] > 0) / len(trades_list) if trades_list else 0
        }

    def _handle_tool_call(self, tool_name: str, tool_input: Dict) -> str:
        """Handle a tool call from the LLM."""
        if tool_name in self.tool_handlers:
            result = self.tool_handlers[tool_name](**tool_input)
            return json.dumps(result)
        return json.dumps({"error": f"Unknown tool: {tool_name}"})

    # =========================================================================
    # CLAUDE API METHODS
    # =========================================================================

    def _call_claude(
        self,
        system_prompt: str,
        user_message: str,
        use_tools: bool = False
    ) -> str:
        """
        Call Claude API with optional tool use.

        Args:
            system_prompt: System instructions
            user_message: User query
            use_tools: Whether to enable tool calling

        Returns:
            Model response text
        """
        if self.anthropic_client is None:
            return self._call_openai_fallback(system_prompt, user_message)

        messages = [{"role": "user", "content": user_message}]

        kwargs = {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "system": system_prompt,
            "messages": messages
        }

        if use_tools:
            kwargs["tools"] = AVAILABLE_TOOLS

        # Initial call
        response = self.anthropic_client.messages.create(**kwargs)

        # Handle tool use loop
        while response.stop_reason == "tool_use":
            # Process tool calls
            tool_results = []
            assistant_content = response.content

            for block in response.content:
                if block.type == "tool_use":
                    tool_result = self._handle_tool_call(block.name, block.input)
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": block.id,
                        "content": tool_result
                    })

            # Continue conversation with tool results
            messages.append({"role": "assistant", "content": assistant_content})
            messages.append({"role": "user", "content": tool_results})

            kwargs["messages"] = messages
            response = self.anthropic_client.messages.create(**kwargs)

        # Extract text from response
        for block in response.content:
            if hasattr(block, 'text'):
                return block.text

        return ""

    def _call_openai_fallback(self, system_prompt: str, user_message: str) -> str:
        """Fallback to OpenAI if Claude unavailable."""
        if self.openai_client is None:
            return self._generate_placeholder_response()

        response = self.openai_client.chat.completions.create(
            model=self.fallback_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=self.max_tokens,
            temperature=self.temperature
        )

        return response.choices[0].message.content

    def _generate_placeholder_response(self) -> str:
        """Generate placeholder when no API available."""
        return json.dumps({
            "error": "No LLM API available",
            "recommendation": "HOLD",
            "confidence": 0.0,
            "rationale": "Unable to generate analysis - API keys not configured"
        })

    # =========================================================================
    # PUBLIC ANALYSIS METHODS
    # =========================================================================

    def generate_trade_recommendation(
        self,
        context: AnalysisContext,
        use_tools: bool = True
    ) -> TradeRecommendation:
        """
        Generate trade recommendation from context.

        Args:
            context: AnalysisContext with all relevant data
            use_tools: Whether to allow tool calls for additional data

        Returns:
            TradeRecommendation object
        """
        # Build user message with context
        user_message = f"""
Analyse the following market data and provide a trading recommendation:

TICKER: {context.ticker}
CURRENT PRICE: ${context.current_price:.2f}
DATE: {context.current_date}

TECHNICAL INDICATORS:
- RSI: {context.rsi:.1f}
- MACD: {context.macd:.4f}
- MACD Signal: {context.macd_signal:.4f}
- MACD Histogram: {context.macd - context.macd_signal:.4f}
- SMA 50: ${context.sma_50:.2f}
- SMA 200: ${context.sma_200:.2f}
- Price vs SMA50: {(context.current_price / context.sma_50 - 1) * 100:.1f}%
- Price vs SMA200: {(context.current_price / context.sma_200 - 1) * 100:.1f}%
- BB %B: {context.bb_percent_b:.2f}
- ATR: ${context.atr:.2f} ({context.atr / context.current_price * 100:.1f}%)
- ADX: {context.adx:.1f}

REGIME ANALYSIS:
- Market Regime: {context.market_regime}
- Volatility Regime: {context.volatility_regime}
- Trend Persistence: {context.trend_persistence}
- Hurst Exponent: {context.hurst_exponent:.3f}
- Regime Confidence: {context.regime_confidence:.1%}

SIGNAL SYSTEM:
- Current Signal: {context.signal}
- Signal Confidence: {context.signal_confidence:.1%}
- Confluence Score: {context.confluence_score:.2f}
- Active Strategy: {context.strategy}
"""
        # Add backtest metrics if available (for performance analysis section)
        if context.cagr is not None:
            sortino_str = f"{context.sortino_ratio:.2f}" if context.sortino_ratio else "N/A"
            user_message += f"""
BACKTEST PERFORMANCE METRICS:
- CAGR: {context.cagr:.1%}
- Sharpe Ratio: {context.sharpe_ratio:.2f}
- Sortino Ratio: {sortino_str}
- Max Drawdown: {context.max_drawdown:.1%}
- Win Rate: {context.win_rate:.1%}
- Profit Factor: {context.profit_factor:.2f}
- Total Trades: {context.total_trades}
"""
        # Add Monte Carlo results if available
        if context.mc_cagr_percentile is not None:
            user_message += f"""
MONTE CARLO ANALYSIS:
- CAGR Percentile: {context.mc_cagr_percentile:.0f}th (vs random)
- Statistically Significant: {"Yes" if context.mc_is_significant else "No"}
- Probability of 10%+ Loss: {context.mc_prob_loss:.1%}
"""
        user_message += """
Provide your analysis following the chain-of-thought framework and output in JSON format.
"""

        # Format the prompt with signal system data
        formatted_prompt = self.TRADE_ANALYSIS_PROMPT.format(
            signal=context.signal,
            confluence=context.confluence_score,
            confidence=context.signal_confidence
        )

        response = self._call_claude(
            formatted_prompt,
            user_message,
            use_tools=use_tools
        )

        # Parse response
        return self._parse_trade_recommendation(response, context)

    def _parse_trade_recommendation(
        self,
        response: str,
        context: AnalysisContext
    ) -> TradeRecommendation:
        """Parse LLM response into TradeRecommendation."""
        try:
            # Try to extract JSON from response
            json_str = response
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0]

            data = json.loads(json_str)

            # Map recommendation string to enum
            rec_map = {
                'STRONG_BUY': Recommendation.STRONG_BUY,
                'BUY': Recommendation.BUY,
                'HOLD': Recommendation.HOLD,
                'SELL': Recommendation.SELL,
                'STRONG_SELL': Recommendation.STRONG_SELL
            }

            # Handle None values from LLM (e.g., when signal is HOLD, it may not provide trade specs)
            entry_price = data.get('entry_price') or context.current_price
            stop_loss = data.get('stop_loss') or context.current_price * 0.95
            take_profit = data.get('take_profit') or context.current_price * 1.10
            position_size = data.get('position_size_pct') or 0.1
            risk_reward = data.get('risk_reward_ratio') or 2.0
            confidence = data.get('confidence') or 0.5

            # Extract new fields with defaults
            technical_summary = data.get('technical_analysis_summary', '')
            investment_thesis = data.get('investment_thesis', '')
            scenarios = data.get('scenarios', None)
            target_1 = data.get('target_1') or context.target_1
            target_2 = data.get('target_2') or context.target_2
            target_3 = data.get('target_3') or context.target_3
            support_levels = data.get('support_levels', [])
            resistance_levels = data.get('resistance_levels', [])

            # Extract performance analysis (merged from separate API call)
            performance_analysis = data.get('performance_analysis', None)

            # Extract enhanced analysis fields (v2)
            rationale_breakdown = data.get('rationale_breakdown', None)
            timeframe_analysis = data.get('timeframe_analysis', None)
            stop_loss_reasoning = data.get('stop_loss_reasoning', '')
            target_1_reasoning = data.get('target_1_reasoning', '')
            target_2_reasoning = data.get('target_2_reasoning', '')
            target_3_reasoning = data.get('target_3_reasoning', '')
            confidence_breakdown = data.get('confidence_breakdown', None)
            chart_patterns = data.get('chart_patterns', None)
            invalidation_conditions = data.get('invalidation_conditions', None)

            return TradeRecommendation(
                recommendation=rec_map.get(data.get('recommendation', 'HOLD'), Recommendation.HOLD),
                confidence=float(confidence),
                rationale=data.get('rationale', ''),
                entry_price=float(entry_price),
                stop_loss=float(stop_loss),
                take_profit=float(take_profit),
                position_size_pct=float(position_size),
                risk_reward_ratio=float(risk_reward),
                risks=data.get('risks', []),
                catalysts=data.get('catalysts', []),
                time_horizon=data.get('time_horizon', 'swing'),
                technical_analysis_summary=technical_summary,
                target_1=float(target_1) if target_1 else None,
                target_2=float(target_2) if target_2 else None,
                target_3=float(target_3) if target_3 else None,
                scenarios=scenarios,
                investment_thesis=investment_thesis,
                support_levels=support_levels,
                resistance_levels=resistance_levels,
                performance_analysis=performance_analysis,
                rationale_breakdown=rationale_breakdown,
                timeframe_analysis=timeframe_analysis,
                stop_loss_reasoning=stop_loss_reasoning,
                target_1_reasoning=target_1_reasoning,
                target_2_reasoning=target_2_reasoning,
                target_3_reasoning=target_3_reasoning,
                confidence_breakdown=confidence_breakdown,
                chart_patterns=chart_patterns,
                invalidation_conditions=invalidation_conditions
            )

        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # Return default recommendation on parse error
            warnings.warn(f"Failed to parse LLM response: {e}")
            return TradeRecommendation(
                recommendation=Recommendation.HOLD,
                confidence=0.0,
                rationale=f"Parse error: {str(e)}. Raw response: {response[:500]}",
                entry_price=context.current_price,
                stop_loss=context.current_price * 0.95,
                take_profit=context.current_price * 1.05,
                position_size_pct=0.0,
                risk_reward_ratio=1.0,
                risks=["Unable to parse LLM response"],
                catalysts=[],
                time_horizon="swing"
            )

    def analyse_performance(
        self,
        context: AnalysisContext,
        performance_report: Optional[Any] = None,
        mc_result: Optional[Any] = None
    ) -> PerformanceAnalysis:
        """
        Analyse strategy performance.

        Args:
            context: AnalysisContext with performance metrics
            performance_report: Optional PerformanceReport object
            mc_result: Optional MonteCarloResult object

        Returns:
            PerformanceAnalysis object
        """
        # Build performance summary
        perf_section = ""
        if context.cagr is not None:
            perf_section = f"""
PERFORMANCE METRICS:
- CAGR: {context.cagr:.1%}
- Sharpe Ratio: {context.sharpe_ratio:.2f}
- Max Drawdown: {context.max_drawdown:.1%}
- Win Rate: {context.win_rate:.1%}
- Profit Factor: {context.profit_factor:.2f}
- Total Trades: {context.total_trades}
"""

        mc_section = ""
        if context.mc_cagr_percentile is not None:
            mc_section = f"""
MONTE CARLO ANALYSIS:
- CAGR Percentile: {context.mc_cagr_percentile:.0f}th
- Statistically Significant: {"Yes" if context.mc_is_significant else "No"}
- Probability of 10%+ Loss: {context.mc_prob_loss:.1%}
"""

        user_message = f"""
Analyse the following strategy performance:

{perf_section}
{mc_section}

CURRENT MARKET CONTEXT:
- Market Regime: {context.market_regime}
- Volatility Regime: {context.volatility_regime}
- Active Strategy: {context.strategy}

Provide institutional-quality assessment in JSON format.
"""

        response = self._call_claude(
            self.PERFORMANCE_ANALYSIS_PROMPT,
            user_message,
            use_tools=False
        )

        return self._parse_performance_analysis(response)

    def _parse_performance_analysis(self, response: str) -> PerformanceAnalysis:
        """Parse LLM response into PerformanceAnalysis."""
        try:
            json_str = response
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0]

            data = json.loads(json_str)

            return PerformanceAnalysis(
                summary=data.get('summary', ''),
                strengths=data.get('strengths', []),
                weaknesses=data.get('weaknesses', []),
                attribution=data.get('attribution', {}),
                warnings=data.get('warnings', []),
                suggestions=data.get('suggestions', []),
                overall_assessment=data.get('overall_assessment', 'fair'),
                confidence_in_edge=float(data.get('confidence_in_edge', 0.5))
            )

        except (json.JSONDecodeError, KeyError, ValueError) as e:
            warnings.warn(f"Failed to parse performance analysis: {e}")
            return PerformanceAnalysis(
                summary=f"Parse error: {str(e)}",
                strengths=[],
                weaknesses=["Unable to parse LLM response"],
                attribution={},
                warnings=["Analysis may be incomplete"],
                suggestions=[],
                overall_assessment="unknown",
                confidence_in_edge=0.0
            )

    def generate_full_report(
        self,
        context: AnalysisContext,
        include_performance: bool = True,
        recommendation: Optional[TradeRecommendation] = None
    ) -> str:
        """
        Generate comprehensive trade report.

        Args:
            context: AnalysisContext with all data
            include_performance: Whether to include performance analysis
            recommendation: Optional pre-computed recommendation (avoids duplicate API call)

        Returns:
            Formatted markdown report
        """
        # Use provided recommendation or generate new one (single API call)
        if recommendation is None:
            recommendation = self.generate_trade_recommendation(context)

        # Performance analysis is now embedded in the recommendation (no separate API call)
        performance = None
        if include_performance and recommendation.performance_analysis:
            # Convert dict to PerformanceAnalysis object for compatibility
            pa = recommendation.performance_analysis
            performance = PerformanceAnalysis(
                summary=pa.get('summary', ''),
                strengths=pa.get('strengths', []),
                weaknesses=pa.get('weaknesses', []),
                attribution=pa.get('attribution', {}),
                warnings=pa.get('warnings', []),
                suggestions=pa.get('suggestions', []),
                overall_assessment=pa.get('overall_assessment', 'fair'),
                confidence_in_edge=float(pa.get('confidence_in_edge', 0.5))
            )

        # Build report
        report = self._format_report(context, recommendation, performance)

        return report

    def _format_report(
        self,
        context: AnalysisContext,
        recommendation: TradeRecommendation,
        performance: Optional[PerformanceAnalysis]
    ) -> str:
        """Format analysis into professional report."""

        # Recommendation colour coding
        rec_emoji = {
            Recommendation.STRONG_BUY: "+++",
            Recommendation.BUY: "++",
            Recommendation.HOLD: "~",
            Recommendation.SELL: "--",
            Recommendation.STRONG_SELL: "---"
        }

        report = f"""
================================================================================
                        TRADE ANALYSIS REPORT
                        {context.ticker} | {context.current_date}
================================================================================

EXECUTIVE SUMMARY
--------------------------------------------------------------------------------
Recommendation: {recommendation.recommendation.value} {rec_emoji.get(recommendation.recommendation, '')}
Confidence: {recommendation.confidence:.0%}
Time Horizon: {recommendation.time_horizon.upper()}

{recommendation.rationale}

TRADE SPECIFICATIONS
--------------------------------------------------------------------------------
Entry Price:     ${recommendation.entry_price:,.2f}
Stop Loss:       ${recommendation.stop_loss:,.2f} ({(recommendation.stop_loss/recommendation.entry_price - 1)*100:+.1f}%)
Take Profit:     ${recommendation.take_profit:,.2f} ({(recommendation.take_profit/recommendation.entry_price - 1)*100:+.1f}%)
Position Size:   {recommendation.position_size_pct:.0%} of portfolio
Risk/Reward:     1:{recommendation.risk_reward_ratio:.1f}

TECHNICAL ANALYSIS
--------------------------------------------------------------------------------
Momentum:
  - RSI: {context.rsi:.1f} {'(Oversold)' if context.rsi < 30 else '(Overbought)' if context.rsi > 70 else '(Neutral)'}
  - MACD: {context.macd:.4f} vs Signal: {context.macd_signal:.4f}
  - MACD Histogram: {context.macd - context.macd_signal:+.4f}

Trend:
  - Price vs SMA50: {(context.current_price/context.sma_50 - 1)*100:+.1f}%
  - Price vs SMA200: {(context.current_price/context.sma_200 - 1)*100:+.1f}%
  - ADX: {context.adx:.1f} {'(Strong Trend)' if context.adx > 25 else '(Weak Trend)'}

Volatility:
  - ATR: ${context.atr:.2f} ({context.atr/context.current_price*100:.1f}% of price)
  - BB %B: {context.bb_percent_b:.2f}

REGIME CONTEXT
--------------------------------------------------------------------------------
Market Regime:     {context.market_regime}
Volatility Regime: {context.volatility_regime}
Trend Persistence: {context.trend_persistence}
Hurst Exponent:    {context.hurst_exponent:.3f} {'(Trending)' if context.hurst_exponent > 0.5 else '(Mean-Reverting)'}
Confidence:        {context.regime_confidence:.0%}

RISK FACTORS
--------------------------------------------------------------------------------
"""
        for i, risk in enumerate(recommendation.risks, 1):
            report += f"  {i}. {risk}\n"

        if recommendation.catalysts:
            report += """
POTENTIAL CATALYSTS
--------------------------------------------------------------------------------
"""
            for i, catalyst in enumerate(recommendation.catalysts, 1):
                report += f"  {i}. {catalyst}\n"

        if performance:
            report += f"""
PERFORMANCE ANALYSIS
--------------------------------------------------------------------------------
Overall Assessment: {performance.overall_assessment.upper()}
Confidence in Edge: {performance.confidence_in_edge:.0%}

{performance.summary}

Strengths:
"""
            for strength in performance.strengths:
                report += f"  + {strength}\n"

            report += "\nWeaknesses:\n"
            for weakness in performance.weaknesses:
                report += f"  - {weakness}\n"

            if performance.warnings:
                report += "\nWarnings:\n"
                for warning in performance.warnings:
                    report += f"  ! {warning}\n"

            if performance.suggestions:
                report += "\nSuggestions:\n"
                for suggestion in performance.suggestions:
                    report += f"  > {suggestion}\n"

        report += """
================================================================================
                        END OF REPORT
================================================================================
"""

        return report

    def generate_json_report(
        self,
        context: AnalysisContext,
        include_performance: bool = True,
        recommendation: Optional[TradeRecommendation] = None
    ) -> Dict[str, Any]:
        """
        Generate comprehensive trade analysis as structured JSON.

        This is the primary output method for feeding into a master agent.
        Returns a complete JSON-serializable dictionary with all analysis data.

        Args:
            context: AnalysisContext with all data
            include_performance: Whether to include performance analysis
            recommendation: Optional pre-computed recommendation (avoids duplicate API call)

        Returns:
            Dictionary with complete analysis, ready for JSON serialization
        """
        # Use provided recommendation or generate new one (single API call)
        if recommendation is None:
            recommendation = self.generate_trade_recommendation(context)

        # Performance analysis is now embedded in recommendation (no separate API call)

        # Build structured output
        output = {
            "metadata": {
                "ticker": context.ticker,
                "analysis_date": context.current_date,
                "current_price": context.current_price,
                "generated_by": "LLMAgent",
                "model": self.model if self.anthropic_client else self.fallback_model
            },
            "recommendation": {
                "action": recommendation.recommendation.value,
                "confidence": recommendation.confidence,
                "time_horizon": recommendation.time_horizon,
                "rationale": recommendation.rationale
            },
            "trade_specifications": {
                "entry_price": recommendation.entry_price,
                "stop_loss": recommendation.stop_loss,
                "stop_loss_pct": (recommendation.stop_loss / recommendation.entry_price - 1) * 100,
                "take_profit": recommendation.take_profit,
                "take_profit_pct": (recommendation.take_profit / recommendation.entry_price - 1) * 100,
                "position_size_pct": recommendation.position_size_pct,
                "risk_reward_ratio": recommendation.risk_reward_ratio
            },
            "technical_analysis": {
                "momentum": {
                    "rsi": context.rsi,
                    "rsi_signal": "oversold" if context.rsi < 30 else "overbought" if context.rsi > 70 else "neutral",
                    "macd": context.macd,
                    "macd_signal": context.macd_signal,
                    "macd_histogram": context.macd - context.macd_signal
                },
                "trend": {
                    "sma_50": context.sma_50,
                    "sma_200": context.sma_200,
                    "price_vs_sma50_pct": (context.current_price / context.sma_50 - 1) * 100,
                    "price_vs_sma200_pct": (context.current_price / context.sma_200 - 1) * 100,
                    "adx": context.adx,
                    "trend_strength": "strong" if context.adx > 25 else "weak"
                },
                "volatility": {
                    "atr": context.atr,
                    "atr_pct": context.atr / context.current_price * 100,
                    "bb_percent_b": context.bb_percent_b
                }
            },
            "regime_analysis": {
                "market_regime": context.market_regime,
                "volatility_regime": context.volatility_regime,
                "trend_persistence": context.trend_persistence,
                "hurst_exponent": context.hurst_exponent,
                "hurst_interpretation": "trending" if context.hurst_exponent > 0.55 else ("mean_reverting" if context.hurst_exponent < 0.45 else "random_walk"),
                "regime_confidence": context.regime_confidence
            },
            "signal_system": {
                "current_signal": context.signal,
                "signal_confidence": context.signal_confidence,
                "confluence_score": context.confluence_score,
                "active_strategy": context.strategy
            },
            "risk_factors": recommendation.risks,
            "catalysts": recommendation.catalysts
        }

        # Add enhanced analysis fields
        if recommendation.technical_analysis_summary:
            output["technical_analysis"]["summary"] = recommendation.technical_analysis_summary

        if recommendation.investment_thesis:
            output["investment_thesis"] = recommendation.investment_thesis

        # Add multi-target price levels
        if recommendation.target_1 is not None:
            output["trade_specifications"]["target_1"] = recommendation.target_1
            output["trade_specifications"]["target_2"] = recommendation.target_2
            output["trade_specifications"]["target_3"] = recommendation.target_3
            output["trade_specifications"]["target_1_pct"] = (recommendation.target_1 / recommendation.entry_price - 1) * 100
            output["trade_specifications"]["target_2_pct"] = (recommendation.target_2 / recommendation.entry_price - 1) * 100
            output["trade_specifications"]["target_3_pct"] = (recommendation.target_3 / recommendation.entry_price - 1) * 100

        # Add scenario analysis
        if recommendation.scenarios:
            output["scenario_analysis"] = recommendation.scenarios

        # Add support/resistance levels
        if recommendation.support_levels:
            output["key_levels"] = {
                "support": recommendation.support_levels,
                "resistance": recommendation.resistance_levels
            }

        # Add enhanced analysis fields (v2)
        if recommendation.rationale_breakdown:
            output["rationale_breakdown"] = recommendation.rationale_breakdown

        if recommendation.timeframe_analysis:
            output["timeframe_analysis"] = recommendation.timeframe_analysis

        if recommendation.stop_loss_reasoning:
            output["trade_specifications"]["stop_loss_reasoning"] = recommendation.stop_loss_reasoning

        if recommendation.target_1_reasoning:
            output["trade_specifications"]["target_1_reasoning"] = recommendation.target_1_reasoning
            output["trade_specifications"]["target_2_reasoning"] = recommendation.target_2_reasoning
            output["trade_specifications"]["target_3_reasoning"] = recommendation.target_3_reasoning

        if recommendation.confidence_breakdown:
            output["confidence_breakdown"] = recommendation.confidence_breakdown

        if recommendation.chart_patterns:
            output["chart_patterns"] = recommendation.chart_patterns

        if recommendation.invalidation_conditions:
            output["invalidation_conditions"] = recommendation.invalidation_conditions

        # Add component scores if available
        if context.overall_score is not None:
            output["component_scores"] = {
                "overall": context.overall_score,
                "momentum": context.momentum_score,
                "trend": context.trend_score,
                "volatility": context.volatility_score,
                "volume": context.volume_score
            }

        # Add additional technical levels
        if context.bb_upper is not None:
            output["technical_analysis"]["levels"] = {
                "bb_upper": context.bb_upper,
                "bb_middle": context.bb_middle,
                "bb_lower": context.bb_lower
            }
            if context.volume_ratio is not None:
                output["technical_analysis"]["volume_ratio"] = context.volume_ratio

        # Add performance analysis if available (now embedded in recommendation)
        if include_performance and recommendation.performance_analysis:
            output["performance_analysis"] = recommendation.performance_analysis

        # Add comprehensive backtest metrics if available
        if context.cagr is not None:
            output["backtest_metrics"] = {
                "return_metrics": {
                    "total_return": context.total_return,
                    "cagr": context.cagr,
                    "volatility": context.volatility
                },
                "risk_adjusted_metrics": {
                    "sharpe_ratio": context.sharpe_ratio,
                    "sortino_ratio": context.sortino_ratio,
                    "calmar_ratio": context.calmar_ratio,
                    "omega_ratio": context.omega_ratio,
                    "profit_factor": context.profit_factor
                },
                "risk_metrics": {
                    "max_drawdown": context.max_drawdown,
                    "var_95": context.var_95,
                    "var_99": context.var_99,
                    "cvar_95": context.cvar_95,
                    "cvar_975": context.cvar_975
                },
                "probabilistic_metrics": {
                    "probabilistic_sharpe": context.probabilistic_sharpe,
                    "deflated_sharpe": context.deflated_sharpe,
                    "sharpe_confidence_interval": {
                        "lower": context.sharpe_ci_lower,
                        "upper": context.sharpe_ci_upper
                    }
                },
                "trade_statistics": {
                    "total_trades": context.total_trades,
                    "win_rate": context.win_rate,
                    "avg_win": context.avg_win,
                    "avg_loss": context.avg_loss,
                    "best_trade": context.best_trade,
                    "worst_trade": context.worst_trade,
                    "avg_trade_duration": context.avg_trade_duration
                },
                "statistical_tests": {
                    "cagr_tstat": context.cagr_tstat,
                    "cagr_pvalue": context.cagr_pvalue,
                    "returns_skewness": context.returns_skewness,
                    "returns_kurtosis": context.returns_kurtosis,
                    "jarque_bera_stat": context.jarque_bera_stat,
                    "jarque_bera_pvalue": context.jarque_bera_pvalue,
                    "returns_normally_distributed": context.jarque_bera_pvalue > 0.05 if context.jarque_bera_pvalue else None
                },
                "time_period": {
                    "start_date": context.start_date,
                    "end_date": context.end_date,
                    "trading_days": context.trading_days,
                    "years": context.years
                }
            }

        # Add comprehensive Monte Carlo results if available
        if context.mc_cagr_percentile is not None:
            output["monte_carlo"] = {
                "statistical_significance": {
                    "cagr_percentile": context.mc_cagr_percentile,
                    "is_statistically_significant": context.mc_is_significant,
                    "probability_of_loss": context.mc_prob_loss
                },
                "cagr_distribution": {
                    "percentile_5th": context.mc_cagr_5th,
                    "percentile_25th": context.mc_cagr_25th,
                    "percentile_50th_median": context.mc_cagr_50th,
                    "percentile_75th": context.mc_cagr_75th,
                    "percentile_95th": context.mc_cagr_95th
                },
                "other_metrics": {
                    "sharpe_median": context.mc_sharpe_median,
                    "max_drawdown_median": context.mc_max_dd_median
                }
            }

        # Add position sizing metrics if available
        if context.full_kelly is not None or context.garch_volatility is not None:
            output["position_sizing"] = {
                "full_kelly": context.full_kelly,
                "fractional_kelly": context.fractional_kelly,
                "kelly_multiplier": context.kelly_multiplier,
                "garch_volatility_forecast": context.garch_volatility,
                "volatility_adjusted_size": context.vol_adjusted_size
            }

        return output

    def generate_json_string(
        self,
        context: AnalysisContext,
        include_performance: bool = True,
        indent: int = 2
    ) -> str:
        """
        Generate JSON string output (convenience wrapper).

        Args:
            context: AnalysisContext with all data
            include_performance: Whether to include performance analysis
            indent: JSON indentation level (None for compact)

        Returns:
            JSON string
        """
        data = self.generate_json_report(context, include_performance)
        return json.dumps(data, indent=indent, default=str)

    # =========================================================================
    # FILE OUTPUT METHODS
    # =========================================================================

    def save_all_outputs(
        self,
        context: AnalysisContext,
        output_dir: str = None,
        analyst_name: str = "Fardeen Idrus",
        agent_name: str = "Technical Analyst Agent",
        include_performance: bool = True
    ) -> Dict[str, str]:
        """
        Save analysis to JSON, TXT, and PDF files.

        Args:
            context: AnalysisContext with all data
            output_dir: Directory to save outputs (defaults to project_root/outputs)
            analyst_name: Name of the analyst for PDF header
            agent_name: Name of the agent for PDF header
            include_performance: Whether to include performance analysis

        Returns:
            Dictionary with paths to saved files
        """
        # Default to project_root/outputs (one level up from src/)
        # Save to shared_outputs at master repo root
        if output_dir is None:
            # Go up 4 levels: llm_agent.py â†’ src â†’ fardeen_technical_agent â†’ technical_agents â†’ master-analyst-agent
            master_repo_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
            output_dir = os.path.join(master_repo_root, "shared_outputs")

        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # Use ticker as filename (overwrites existing files)
        base_filename = f"technical_fardeen_{context.ticker}"

        # Generate recommendation ONCE (single API call)
        recommendation = self.generate_trade_recommendation(context)

        # Generate JSON report (reuses recommendation, no additional API call)
        json_data = self.generate_json_report(context, include_performance, recommendation=recommendation)

        # Save JSON only
        paths = {}
        json_path = os.path.join(output_dir, f"{base_filename}.json")
        paths['json'] = self._save_json(json_data, json_path)

        print(f"\nOutput saved: {json_path}")

        return paths

    def _save_json(self, data: Dict[str, Any], filepath: str) -> str:
        """Save JSON data to file."""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)
        return filepath

    def _save_txt(
        self,
        report: str,
        filepath: str,
        analyst_name: str,
        agent_name: str
    ) -> str:
        """Save text report to file with header."""
        header = f"""
{'=' * 80}
{agent_name.upper()}
{'=' * 80}
Analyst: {analyst_name}
Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
{'=' * 80}
"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(header)
            f.write(report)
        return filepath

    def _save_pdf(
        self,
        json_data: Dict[str, Any],
        text_report: str,
        filepath: str,
        analyst_name: str = "Fardeen Idrus",
        agent_name: str = "Technical Analyst Agent"
    ) -> str:
        """
        Generate and save professionally formatted PDF report.

        Args:
            json_data: Structured analysis data
            text_report: Text version of report
            filepath: Output path for PDF
            analyst_name: Name of the analyst
            agent_name: Name of the agent

        Returns:
            Path to saved PDF
        """
        try:
            from reportlab.lib import colors
            from reportlab.lib.pagesizes import A4
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch, cm
            from reportlab.platypus import (
                SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle,
                PageBreak, HRFlowable
            )
            from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
        except ImportError:
            warnings.warn("reportlab not installed. PDF generation skipped. Install with: pip install reportlab")
            # Fall back to saving text as a simple file
            with open(filepath.replace('.pdf', '_fallback.txt'), 'w') as f:
                f.write(text_report)
            return filepath.replace('.pdf', '_fallback.txt')

        # Create document
        doc = SimpleDocTemplate(
            filepath,
            pagesize=A4,
            rightMargin=1*inch,
            leftMargin=1*inch,
            topMargin=1*inch,
            bottomMargin=1*inch
        )

        # Styles
        styles = getSampleStyleSheet()

        # Custom styles
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=24,
            spaceAfter=6,
            alignment=TA_CENTER,
            textColor=colors.HexColor('#1a365d')
        )

        subtitle_style = ParagraphStyle(
            'CustomSubtitle',
            parent=styles['Normal'],
            fontSize=12,
            spaceAfter=20,
            alignment=TA_CENTER,
            textColor=colors.HexColor('#4a5568')
        )

        section_style = ParagraphStyle(
            'SectionHeader',
            parent=styles['Heading2'],
            fontSize=14,
            spaceBefore=20,
            spaceAfter=10,
            textColor=colors.HexColor('#2d3748'),
            borderPadding=5
        )

        body_style = ParagraphStyle(
            'CustomBody',
            parent=styles['Normal'],
            fontSize=10,
            spaceAfter=8,
            leading=14
        )

        # Build document content
        content = []

        # Header
        content.append(Paragraph(agent_name, title_style))
        content.append(Paragraph(
            f"Analysis by: <b>{analyst_name}</b>",
            subtitle_style
        ))
        content.append(Paragraph(
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ParagraphStyle('DateStyle', parent=body_style, alignment=TA_CENTER)
        ))

        # Horizontal line
        content.append(Spacer(1, 10))
        content.append(HRFlowable(
            width="100%",
            thickness=2,
            color=colors.HexColor('#1a365d'),
            spaceBefore=5,
            spaceAfter=15
        ))

        # Executive Summary
        rec = json_data['recommendation']
        content.append(Paragraph("EXECUTIVE SUMMARY", section_style))

        # Recommendation box
        rec_color = {
            'STRONG_BUY': colors.HexColor('#22543d'),
            'BUY': colors.HexColor('#276749'),
            'HOLD': colors.HexColor('#744210'),
            'SELL': colors.HexColor('#9b2c2c'),
            'STRONG_SELL': colors.HexColor('#742a2a')
        }.get(rec['action'], colors.gray)

        summary_data = [
            ['Ticker', json_data['metadata']['ticker']],
            ['Current Price', f"${json_data['metadata']['current_price']:,.2f}"],
            ['Recommendation', rec['action']],
            ['Confidence', f"{rec['confidence']:.0%}"],
            ['Time Horizon', rec['time_horizon'].upper()]
        ]

        summary_table = Table(summary_data, colWidths=[2*inch, 3*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#f7fafc')),
            ('TEXTCOLOR', (0, 0), (0, -1), colors.HexColor('#2d3748')),
            ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
            ('FONTNAME', (1, 0), (1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
            ('TOPPADDING', (0, 0), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
            ('LEFTPADDING', (0, 0), (-1, -1), 10),
        ]))
        content.append(summary_table)

        content.append(Spacer(1, 15))
        content.append(Paragraph(f"<b>Rationale:</b> {rec['rationale']}", body_style))

        # Investment Thesis (if available)
        if 'investment_thesis' in json_data and json_data['investment_thesis']:
            content.append(Spacer(1, 10))
            content.append(Paragraph(f"<b>Investment Thesis:</b> {json_data['investment_thesis']}", body_style))

        # Technical Analysis Summary (narrative paragraph - if available)
        tech_summary = json_data.get('technical_analysis', {}).get('summary', '')
        if tech_summary:
            content.append(Spacer(1, 15))
            content.append(Paragraph("TECHNICAL ANALYSIS SUMMARY", section_style))
            content.append(Paragraph(tech_summary, body_style))

        # Component Scores (if available)
        if 'component_scores' in json_data:
            scores = json_data['component_scores']
            content.append(Spacer(1, 15))
            content.append(Paragraph("COMPONENT SCORES", section_style))

            # Score color helper
            def get_score_color(score):
                if score >= 70:
                    return colors.HexColor('#22543d')  # Green
                elif score >= 50:
                    return colors.HexColor('#744210')  # Yellow/Orange
                else:
                    return colors.HexColor('#9b2c2c')  # Red

            scores_data = [
                ['Component', 'Score', 'Assessment'],
                ['Momentum', f"{scores.get('momentum', 0):.0f}/100", 'Strong' if scores.get('momentum', 0) >= 70 else 'Moderate' if scores.get('momentum', 0) >= 50 else 'Weak'],
                ['Trend', f"{scores.get('trend', 0):.0f}/100", 'Strong' if scores.get('trend', 0) >= 70 else 'Moderate' if scores.get('trend', 0) >= 50 else 'Weak'],
                ['Volatility', f"{scores.get('volatility', 0):.0f}/100", 'Favorable' if scores.get('volatility', 0) >= 70 else 'Moderate' if scores.get('volatility', 0) >= 50 else 'Elevated'],
                ['Volume', f"{scores.get('volume', 0):.0f}/100", 'Strong' if scores.get('volume', 0) >= 70 else 'Average' if scores.get('volume', 0) >= 50 else 'Weak'],
                ['Overall', f"{scores.get('overall', 0):.0f}/100", 'Bullish' if scores.get('overall', 0) >= 70 else 'Neutral' if scores.get('overall', 0) >= 50 else 'Bearish']
            ]

            scores_table = Table(scores_data, colWidths=[1.5*inch, 1.5*inch, 2*inch])
            scores_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 10),
                ('ALIGN', (1, 0), (-1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 6),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f7fafc')])
            ]))
            content.append(scores_table)

        # Scenario Analysis (if available)
        if 'scenario_analysis' in json_data:
            scenarios = json_data['scenario_analysis']
            content.append(Spacer(1, 15))
            content.append(Paragraph("SCENARIO ANALYSIS", section_style))

            # Bull Case
            if 'bull_case' in scenarios:
                bull = scenarios['bull_case']
                content.append(Paragraph(
                    f"<b>Bull Case ({bull.get('probability', 0):.0%} probability):</b> "
                    f"Target ${bull.get('target_price', 0):,.2f} ({bull.get('return_pct', 0):+.1f}%)",
                    body_style
                ))
                drivers = bull.get('drivers', [])
                if drivers:
                    content.append(Paragraph(f"<i>Drivers: {', '.join(drivers)}</i>",
                        ParagraphStyle('DriversStyle', parent=body_style, fontSize=9, textColor=colors.HexColor('#4a5568'))))

            # Base Case
            if 'base_case' in scenarios:
                base = scenarios['base_case']
                content.append(Spacer(1, 5))
                content.append(Paragraph(
                    f"<b>Base Case ({base.get('probability', 0):.0%} probability):</b> "
                    f"Target ${base.get('target_price', 0):,.2f} ({base.get('return_pct', 0):+.1f}%)",
                    body_style
                ))
                drivers = base.get('drivers', [])
                if drivers:
                    content.append(Paragraph(f"<i>Drivers: {', '.join(drivers)}</i>",
                        ParagraphStyle('DriversStyle', parent=body_style, fontSize=9, textColor=colors.HexColor('#4a5568'))))

            # Bear Case
            if 'bear_case' in scenarios:
                bear = scenarios['bear_case']
                content.append(Spacer(1, 5))
                content.append(Paragraph(
                    f"<b>Bear Case ({bear.get('probability', 0):.0%} probability):</b> "
                    f"Target ${bear.get('target_price', 0):,.2f} ({bear.get('return_pct', 0):+.1f}%)",
                    body_style
                ))
                drivers = bear.get('drivers', [])
                if drivers:
                    content.append(Paragraph(f"<i>Drivers: {', '.join(drivers)}</i>",
                        ParagraphStyle('DriversStyle', parent=body_style, fontSize=9, textColor=colors.HexColor('#4a5568'))))

            # Expected Value
            if 'expected_value_pct' in scenarios:
                content.append(Spacer(1, 10))
                ev = scenarios['expected_value_pct']
                ev_color = colors.HexColor('#22543d') if ev > 0 else colors.HexColor('#9b2c2c')
                content.append(Paragraph(
                    f"<b>Probability-Weighted Expected Value: {ev:+.2f}%</b>",
                    ParagraphStyle('EVStyle', parent=body_style, textColor=ev_color, fontSize=11)
                ))

        # Trade Specifications
        content.append(Paragraph("TRADE SPECIFICATIONS", section_style))

        specs = json_data['trade_specifications']
        spec_data = [
            ['Entry Price', f"${specs['entry_price']:,.2f}"],
            ['Stop Loss', f"${specs['stop_loss']:,.2f} ({specs['stop_loss_pct']:+.1f}%)"],
            ['Take Profit', f"${specs['take_profit']:,.2f} ({specs['take_profit_pct']:+.1f}%)"],
            ['Position Size', f"{specs['position_size_pct']:.0%} of portfolio"],
            ['Risk/Reward', f"1:{specs['risk_reward_ratio']:.1f}"]
        ]

        # Add multi-target levels if available
        if specs.get('target_1') is not None:
            entry = specs['entry_price']
            t1_pct = ((specs['target_1'] / entry) - 1) * 100
            spec_data.append(['Target 1 (T1)', f"${specs['target_1']:,.2f} ({t1_pct:+.1f}%)"])
        if specs.get('target_2') is not None:
            entry = specs['entry_price']
            t2_pct = ((specs['target_2'] / entry) - 1) * 100
            spec_data.append(['Target 2 (T2)', f"${specs['target_2']:,.2f} ({t2_pct:+.1f}%)"])
        if specs.get('target_3') is not None:
            entry = specs['entry_price']
            t3_pct = ((specs['target_3'] / entry) - 1) * 100
            spec_data.append(['Target 3 (T3)', f"${specs['target_3']:,.2f} ({t3_pct:+.1f}%)"])

        spec_table = Table(spec_data, colWidths=[2*inch, 3*inch])
        spec_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#f7fafc')),
            ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
            ('TOPPADDING', (0, 0), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ('LEFTPADDING', (0, 0), (-1, -1), 10),
        ]))
        content.append(spec_table)

        # Technical Analysis
        content.append(Paragraph("TECHNICAL ANALYSIS", section_style))

        tech = json_data['technical_analysis']
        tech_data = [
            ['Indicator', 'Value', 'Signal'],
            ['RSI', f"{tech['momentum']['rsi']:.1f}", tech['momentum']['rsi_signal'].upper()],
            ['MACD', f"{tech['momentum']['macd']:.4f}", 'BULLISH' if tech['momentum']['macd_histogram'] > 0 else 'BEARISH'],
            ['ADX', f"{tech['trend']['adx']:.1f}", tech['trend']['trend_strength'].upper()],
            ['Price vs SMA50', f"{tech['trend']['price_vs_sma50_pct']:+.1f}%", 'ABOVE' if tech['trend']['price_vs_sma50_pct'] > 0 else 'BELOW'],
            ['Price vs SMA200', f"{tech['trend']['price_vs_sma200_pct']:+.1f}%", 'ABOVE' if tech['trend']['price_vs_sma200_pct'] > 0 else 'BELOW'],
            ['ATR', f"{tech['volatility']['atr_pct']:.1f}%", '-'],
            ['BB %B', f"{tech['volatility']['bb_percent_b']:.2f}", '-']
        ]

        tech_table = Table(tech_data, colWidths=[1.5*inch, 1.5*inch, 2*inch])
        tech_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 9),
            ('ALIGN', (1, 0), (-1, -1), 'CENTER'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
            ('TOPPADDING', (0, 0), (-1, -1), 5),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f7fafc')])
        ]))
        content.append(tech_table)

        # Regime Analysis
        content.append(Paragraph("REGIME ANALYSIS", section_style))

        regime = json_data['regime_analysis']
        regime_data = [
            ['Market Regime', regime['market_regime']],
            ['Volatility Regime', regime['volatility_regime']],
            ['Trend Persistence', regime['trend_persistence']],
            ['Hurst Exponent', f"{regime['hurst_exponent']:.3f} ({regime['hurst_interpretation'].upper()})"],
            ['Regime Confidence', f"{regime['regime_confidence']:.0%}"]
        ]

        regime_table = Table(regime_data, colWidths=[2*inch, 3*inch])
        regime_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#f7fafc')),
            ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
            ('TOPPADDING', (0, 0), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ('LEFTPADDING', (0, 0), (-1, -1), 10),
        ]))
        content.append(regime_table)

        # Risk Factors
        if json_data['risk_factors']:
            content.append(Paragraph("RISK FACTORS", section_style))
            for i, risk in enumerate(json_data['risk_factors'], 1):
                content.append(Paragraph(f"{i}. {risk}", body_style))

        # Catalysts
        if json_data['catalysts']:
            content.append(Paragraph("POTENTIAL CATALYSTS", section_style))
            for i, catalyst in enumerate(json_data['catalysts'], 1):
                content.append(Paragraph(f"{i}. {catalyst}", body_style))

        # Performance Analysis (if available)
        if 'performance_analysis' in json_data:
            content.append(PageBreak())
            content.append(Paragraph("PERFORMANCE ANALYSIS", section_style))

            perf = json_data['performance_analysis']
            content.append(Paragraph(
                f"<b>Overall Assessment:</b> {perf['overall_assessment'].upper()}",
                body_style
            ))
            content.append(Paragraph(
                f"<b>Confidence in Edge:</b> {perf['confidence_in_edge']:.0%}",
                body_style
            ))
            content.append(Spacer(1, 10))
            content.append(Paragraph(perf['summary'], body_style))

            if perf['strengths']:
                content.append(Spacer(1, 10))
                content.append(Paragraph("<b>Strengths:</b>", body_style))
                for s in perf['strengths']:
                    content.append(Paragraph(f"â€¢ {s}", body_style))

            if perf['weaknesses']:
                content.append(Spacer(1, 10))
                content.append(Paragraph("<b>Weaknesses:</b>", body_style))
                for w in perf['weaknesses']:
                    content.append(Paragraph(f"â€¢ {w}", body_style))

        # Comprehensive Backtest Metrics (if available)
        if 'backtest_metrics' in json_data:
            bt = json_data['backtest_metrics']

            # Return Metrics Section
            content.append(Paragraph("RETURN METRICS", section_style))
            ret = bt.get('return_metrics', {})
            ret_data = [
                ['Metric', 'Value'],
                ['Total Return', f"{ret.get('total_return', 0):.1%}" if ret.get('total_return') else 'N/A'],
                ['CAGR', f"{ret.get('cagr', 0):.1%}" if ret.get('cagr') else 'N/A'],
                ['Volatility (Ann.)', f"{ret.get('volatility', 0):.1%}" if ret.get('volatility') else 'N/A']
            ]
            ret_table = Table(ret_data, colWidths=[2.5*inch, 2.5*inch])
            ret_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('ALIGN', (1, 0), (1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 5),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
            ]))
            content.append(ret_table)

            # Risk-Adjusted Metrics Section
            content.append(Paragraph("RISK-ADJUSTED METRICS", section_style))
            risk_adj = bt.get('risk_adjusted_metrics', {})
            risk_adj_data = [
                ['Metric', 'Value', 'Interpretation'],
                ['Sharpe Ratio', f"{risk_adj.get('sharpe_ratio', 0):.2f}" if risk_adj.get('sharpe_ratio') else 'N/A',
                 'Good' if risk_adj.get('sharpe_ratio', 0) > 1 else 'Fair' if risk_adj.get('sharpe_ratio', 0) > 0.5 else 'Poor'],
                ['Sortino Ratio', f"{risk_adj.get('sortino_ratio', 0):.2f}" if risk_adj.get('sortino_ratio') else 'N/A',
                 'Downside-adjusted'],
                ['Calmar Ratio', f"{risk_adj.get('calmar_ratio', 0):.2f}" if risk_adj.get('calmar_ratio') else 'N/A',
                 'Return/MaxDD'],
                ['Omega Ratio', f"{risk_adj.get('omega_ratio', 0):.2f}" if risk_adj.get('omega_ratio') else 'N/A',
                 'Gain/Loss prob'],
                ['Profit Factor', f"{risk_adj.get('profit_factor', 0):.2f}" if risk_adj.get('profit_factor') else 'N/A',
                 'Good' if risk_adj.get('profit_factor', 0) > 1.5 else 'Fair']
            ]
            risk_adj_table = Table(risk_adj_data, colWidths=[1.5*inch, 1.5*inch, 2*inch])
            risk_adj_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('ALIGN', (1, 0), (-1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 5),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
            ]))
            content.append(risk_adj_table)

            # Risk Metrics (VaR/CVaR) Section
            content.append(Paragraph("RISK METRICS (VaR / CVaR)", section_style))
            risk = bt.get('risk_metrics', {})
            risk_data = [
                ['Metric', 'Value', 'Description'],
                ['Max Drawdown', f"{risk.get('max_drawdown', 0):.1%}" if risk.get('max_drawdown') else 'N/A', 'Worst peak-to-trough'],
                ['VaR (95%)', f"{risk.get('var_95', 0):.2%}" if risk.get('var_95') else 'N/A', 'Daily loss 95% conf'],
                ['VaR (99%)', f"{risk.get('var_99', 0):.2%}" if risk.get('var_99') else 'N/A', 'Daily loss 99% conf'],
                ['CVaR (95%)', f"{risk.get('cvar_95', 0):.2%}" if risk.get('cvar_95') else 'N/A', 'Expected shortfall'],
                ['CVaR (97.5%)', f"{risk.get('cvar_975', 0):.2%}" if risk.get('cvar_975') else 'N/A', 'Tail risk']
            ]
            risk_table = Table(risk_data, colWidths=[1.5*inch, 1.5*inch, 2*inch])
            risk_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#742a2a')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('ALIGN', (1, 0), (-1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 5),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
            ]))
            content.append(risk_table)

            # Trade Statistics Section
            content.append(Paragraph("TRADE STATISTICS", section_style))
            trades = bt.get('trade_statistics', {})
            trades_data = [
                ['Metric', 'Value'],
                ['Total Trades', str(trades.get('total_trades', 0))],
                ['Win Rate', f"{trades.get('win_rate', 0):.1%}" if trades.get('win_rate') else 'N/A'],
                ['Avg Win', f"{trades.get('avg_win', 0):.2%}" if trades.get('avg_win') else 'N/A'],
                ['Avg Loss', f"{trades.get('avg_loss', 0):.2%}" if trades.get('avg_loss') else 'N/A'],
                ['Best Trade', f"{trades.get('best_trade', 0):.2%}" if trades.get('best_trade') else 'N/A'],
                ['Worst Trade', f"{trades.get('worst_trade', 0):.2%}" if trades.get('worst_trade') else 'N/A'],
                ['Avg Trade Duration', f"{trades.get('avg_trade_duration', 0):.1f} days" if trades.get('avg_trade_duration') is not None else 'N/A']
            ]
            trades_table = Table(trades_data, colWidths=[2.5*inch, 2.5*inch])
            trades_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('ALIGN', (1, 0), (1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 5),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
            ]))
            content.append(trades_table)

            # Statistical Tests Section
            content.append(Paragraph("STATISTICAL SIGNIFICANCE", section_style))
            stats = bt.get('statistical_tests', {})
            prob = bt.get('probabilistic_metrics', {})
            sharpe_ci = prob.get('sharpe_confidence_interval', {})
            stats_data = [
                ['Test', 'Value', 'Interpretation'],
                ['CAGR t-stat', f"{stats.get('cagr_tstat', 0):.2f}" if stats.get('cagr_tstat') else 'N/A',
                 'Significant' if abs(stats.get('cagr_tstat', 0)) > 1.96 else 'Not significant'],
                ['CAGR p-value', f"{stats.get('cagr_pvalue', 0):.4f}" if stats.get('cagr_pvalue') else 'N/A',
                 'Significant' if stats.get('cagr_pvalue', 1) < 0.05 else 'Not significant'],
                ['Prob. Sharpe', f"{prob.get('probabilistic_sharpe', 0):.1%}" if prob.get('probabilistic_sharpe') else 'N/A',
                 'P(true Sharpe > 0)'],
                ['Deflated Sharpe', f"{prob.get('deflated_sharpe', 0):.2f}" if prob.get('deflated_sharpe') else 'N/A',
                 'Adjusted for trials'],
                ['Sharpe 95% CI', f"[{sharpe_ci.get('lower', 0):.2f}, {sharpe_ci.get('upper', 0):.2f}]" if sharpe_ci.get('lower') else 'N/A',
                 'Confidence interval'],
                ['Skewness', f"{stats.get('returns_skewness', 0):.2f}" if stats.get('returns_skewness') else 'N/A',
                 'Normal=0'],
                ['Kurtosis', f"{stats.get('returns_kurtosis', 0):.2f}" if stats.get('returns_kurtosis') else 'N/A',
                 'Normal=3'],
                ['Jarque-Bera p', f"{stats.get('jarque_bera_pvalue', 0):.4f}" if stats.get('jarque_bera_pvalue') else 'N/A',
                 'Normal' if stats.get('jarque_bera_pvalue', 0) > 0.05 else 'Non-normal']
            ]
            stats_table = Table(stats_data, colWidths=[1.5*inch, 1.5*inch, 2*inch])
            stats_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('ALIGN', (1, 0), (-1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 5),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
            ]))
            content.append(stats_table)

            # Time Period Section
            time_period = bt.get('time_period', {})
            if time_period.get('start_date'):
                content.append(Paragraph("BACKTEST PERIOD", section_style))
                period_data = [
                    ['Period', 'Value'],
                    ['Start Date', time_period.get('start_date', 'N/A')],
                    ['End Date', time_period.get('end_date', 'N/A')],
                    ['Trading Days', str(time_period.get('trading_days', 0))],
                    ['Years', f"{time_period.get('years', 0):.1f}"]
                ]
                period_table = Table(period_data, colWidths=[2.5*inch, 2.5*inch])
                period_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4a5568')),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 9),
                    ('ALIGN', (1, 0), (1, -1), 'CENTER'),
                    ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                    ('TOPPADDING', (0, 0), (-1, -1), 5),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
                ]))
                content.append(period_table)

        # Comprehensive Monte Carlo Section (if available)
        if 'monte_carlo' in json_data:
            content.append(PageBreak())
            content.append(Paragraph("MONTE CARLO SIMULATION ANALYSIS", section_style))

            mc = json_data['monte_carlo']
            sig = mc.get('statistical_significance', {})
            dist = mc.get('cagr_distribution', {})
            other = mc.get('other_metrics', {})

            # Significance table
            sig_data = [
                ['Statistical Significance', 'Value'],
                ['CAGR Percentile', f"{sig.get('cagr_percentile', 0):.0f}th" if sig.get('cagr_percentile') else 'N/A'],
                ['Statistically Significant', 'Yes' if sig.get('is_statistically_significant') else 'No'],
                ['Probability of 10%+ Loss', f"{sig.get('probability_of_loss', 0):.1%}" if sig.get('probability_of_loss') is not None else 'N/A']
            ]
            sig_table = Table(sig_data, colWidths=[2.5*inch, 2.5*inch])
            sig_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#276749')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 10),
                ('ALIGN', (1, 0), (1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 6),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ]))
            content.append(sig_table)

            # CAGR Distribution table
            if dist:
                content.append(Spacer(1, 15))
                content.append(Paragraph("<b>CAGR Distribution (Bootstrap Simulations)</b>", body_style))
                dist_data = [
                    ['Percentile', '5th', '25th', '50th (Median)', '75th', '95th'],
                    ['CAGR',
                     f"{dist.get('percentile_5th', 0):.1%}" if dist.get('percentile_5th') else 'N/A',
                     f"{dist.get('percentile_25th', 0):.1%}" if dist.get('percentile_25th') else 'N/A',
                     f"{dist.get('percentile_50th_median', 0):.1%}" if dist.get('percentile_50th_median') else 'N/A',
                     f"{dist.get('percentile_75th', 0):.1%}" if dist.get('percentile_75th') else 'N/A',
                     f"{dist.get('percentile_95th', 0):.1%}" if dist.get('percentile_95th') else 'N/A']
                ]
                dist_table = Table(dist_data, colWidths=[1*inch, 0.9*inch, 0.9*inch, 1.2*inch, 0.9*inch, 0.9*inch])
                dist_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4a5568')),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 8),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                    ('TOPPADDING', (0, 0), (-1, -1), 5),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
                ]))
                content.append(dist_table)

            # Other Monte Carlo Metrics
            if other.get('sharpe_median') is not None or other.get('max_drawdown_median') is not None:
                content.append(Spacer(1, 15))
                content.append(Paragraph("<b>Additional Monte Carlo Metrics</b>", body_style))
                other_data = [
                    ['Metric', 'Value', 'Description'],
                    ['Sharpe Median', f"{other.get('sharpe_median', 0):.2f}" if other.get('sharpe_median') is not None else 'N/A',
                     'Median Sharpe from simulations'],
                    ['Max DD Median', f"{other.get('max_drawdown_median', 0):.1%}" if other.get('max_drawdown_median') is not None else 'N/A',
                     'Median max drawdown']
                ]
                other_table = Table(other_data, colWidths=[1.5*inch, 1.5*inch, 2*inch])
                other_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4a5568')),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 9),
                    ('ALIGN', (1, 0), (-1, -1), 'CENTER'),
                    ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                    ('TOPPADDING', (0, 0), (-1, -1), 5),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),
                ]))
                content.append(other_table)

        # Position Sizing Section (if available)
        if 'position_sizing' in json_data:
            content.append(Paragraph("POSITION SIZING ANALYSIS", section_style))
            ps = json_data['position_sizing']
            ps_data = [
                ['Metric', 'Value'],
                ['Full Kelly', f"{ps.get('full_kelly', 0):.1%}" if ps.get('full_kelly') is not None else 'N/A'],
                ['Fractional Kelly', f"{ps.get('fractional_kelly', 0):.1%}" if ps.get('fractional_kelly') is not None else 'N/A'],
                ['GARCH Vol Forecast', f"{ps.get('garch_volatility_forecast', 0):.1%}" if ps.get('garch_volatility_forecast') else 'N/A']
            ]
            ps_table = Table(ps_data, colWidths=[2.5*inch, 2.5*inch])
            ps_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a365d')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 10),
                ('ALIGN', (1, 0), (1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ('TOPPADDING', (0, 0), (-1, -1), 6),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ]))
            content.append(ps_table)

        # Footer
        content.append(Spacer(1, 30))
        content.append(HRFlowable(
            width="100%",
            thickness=1,
            color=colors.HexColor('#e2e8f0'),
            spaceBefore=10,
            spaceAfter=10
        ))
        content.append(Paragraph(
            f"<i>Report generated by {agent_name} | Analyst: {analyst_name}</i>",
            ParagraphStyle('Footer', parent=body_style, alignment=TA_CENTER, fontSize=8, textColor=colors.gray)
        ))

        # Build PDF
        #doc.build(content)

        return filepath

    def get_quick_signal_explanation(self, context: AnalysisContext) -> str:
        """
        Get a quick one-paragraph explanation of the current signal.

        Args:
            context: AnalysisContext

        Returns:
            Brief explanation string
        """
        prompt = f"""In 2-3 sentences, explain why the signal is {context.signal} given:
- RSI: {context.rsi:.1f}
- MACD vs Signal: {context.macd:.4f} vs {context.macd_signal:.4f}
- Market Regime: {context.market_regime}
- Confluence Score: {context.confluence_score:.2f}

Be concise and technical."""

        response = self._call_claude(
            "You are a technical analyst. Provide brief, professional explanations.",
            prompt,
            use_tools=False
        )

        return response


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def calculate_component_scores(data: pd.DataFrame) -> Dict[str, float]:
    """
    Calculate component scores (0-100) for different technical indicator families.

    Scoring methodology:
    - Momentum: RSI position (oversold=high score for buy), MACD histogram direction
    - Trend: ADX strength, price vs SMAs alignment
    - Volatility: BB %B position, ATR percentile
    - Volume: Volume ratio vs average

    Returns:
        Dictionary with momentum_score, trend_score, volatility_score, volume_score, overall_score
    """
    latest = data.iloc[-1]

    # === MOMENTUM SCORE (0-100) ===
    # RSI: Oversold (<30) = bullish = high score, Overbought (>70) = bearish = low score
    rsi = float(latest.get('RSI', 50))
    if rsi <= 30:
        rsi_score = 80 + (30 - rsi) * 0.67  # 80-100 for oversold
    elif rsi >= 70:
        rsi_score = 20 - (rsi - 70) * 0.67  # 0-20 for overbought
    else:
        rsi_score = 50 + (50 - rsi) * 0.75  # 20-80 for neutral zone
    rsi_score = max(0, min(100, rsi_score))

    # MACD histogram: Positive = bullish, negative = bearish
    macd = float(latest.get('MACD', 0))
    macd_signal = float(latest.get('MACD_Signal', 0))
    macd_hist = macd - macd_signal
    # Normalize based on typical range
    macd_score = 50 + min(50, max(-50, macd_hist * 10))

    momentum_score = (rsi_score * 0.6 + macd_score * 0.4)

    # === TREND SCORE (0-100) ===
    # ADX: >25 = strong trend = higher score
    adx = float(latest.get('ADX', 25))
    adx_score = min(100, adx * 2.5)  # ADX 40+ = 100

    # Price vs SMAs: Above both = bullish = high score
    price = float(latest['Close'])
    sma_50 = float(latest.get('SMA_50', price))
    sma_200 = float(latest.get('SMA_200', price))

    sma_score = 50
    if price > sma_50 and price > sma_200:
        sma_score = 75 + min(25, ((price / sma_200) - 1) * 100)  # 75-100
    elif price > sma_50:
        sma_score = 60  # Above 50, below 200
    elif price > sma_200:
        sma_score = 40  # Below 50, above 200
    else:
        sma_score = 25 - min(25, (1 - (price / sma_200)) * 100)  # 0-25
    sma_score = max(0, min(100, sma_score))

    trend_score = (adx_score * 0.4 + sma_score * 0.6)

    # === VOLATILITY SCORE (0-100) ===
    # BB %B: Near 0 = oversold (opportunity), near 1 = overbought
    bb_pct_b = float(latest.get('BB_Percent_B', 0.5))
    if bb_pct_b <= 0.2:
        vol_bb_score = 80 + (0.2 - bb_pct_b) * 100  # High score for oversold
    elif bb_pct_b >= 0.8:
        vol_bb_score = 20 - (bb_pct_b - 0.8) * 100  # Low score for overbought
    else:
        vol_bb_score = 50  # Neutral
    vol_bb_score = max(0, min(100, vol_bb_score))

    # ATR as % of price - lower is generally better for stability
    atr = float(latest.get('ATR', 0))
    atr_pct = (atr / price * 100) if price > 0 else 0
    atr_score = max(0, min(100, 100 - atr_pct * 20))  # Lower ATR% = higher score

    volatility_score = (vol_bb_score * 0.6 + atr_score * 0.4)

    # === VOLUME SCORE (0-100) ===
    volume = float(latest.get('Volume', 0))
    volume_ma = float(latest.get('Volume_MA', volume)) if latest.get('Volume_MA') else volume

    if volume_ma > 0:
        volume_ratio = volume / volume_ma
        # Volume above average = confirmation = higher score
        volume_score = min(100, 50 + (volume_ratio - 1) * 50)
    else:
        volume_score = 50
    volume_score = max(0, min(100, volume_score))

    # === OVERALL SCORE ===
    # Weighted average
    overall_score = (
        momentum_score * 0.30 +
        trend_score * 0.30 +
        volatility_score * 0.20 +
        volume_score * 0.20
    )

    return {
        'momentum_score': round(momentum_score, 1),
        'trend_score': round(trend_score, 1),
        'volatility_score': round(volatility_score, 1),
        'volume_score': round(volume_score, 1),
        'overall_score': round(overall_score, 1)
    }


def calculate_price_targets(data: pd.DataFrame) -> Dict[str, float]:
    """
    Calculate multi-target price levels based on technical indicators.

    Target levels:
    - Target 1 (Conservative): BB middle or nearest resistance
    - Target 2 (Base case): BB upper or 1.5x ATR
    - Target 3 (Aggressive): 2x ATR or prior swing high
    - Stop Loss: BB lower or 1x ATR below

    Returns:
        Dictionary with target_1, target_2, target_3, suggested_stop
    """
    latest = data.iloc[-1]
    price = float(latest['Close'])
    atr = float(latest.get('ATR', price * 0.02))  # Default 2% if no ATR

    # Get Bollinger Band levels
    bb_upper = float(latest.get('BB_Upper', price * 1.02))
    bb_middle = float(latest.get('BB_Middle', price))
    bb_lower = float(latest.get('BB_Lower', price * 0.98))

    # Calculate targets
    target_1 = bb_middle if bb_middle > price else price + atr  # Conservative
    target_2 = bb_upper if bb_upper > price else price + 1.5 * atr  # Base case
    target_3 = price + 2 * atr  # Aggressive

    # Suggested stop
    suggested_stop = max(bb_lower, price - 1.5 * atr)

    return {
        'target_1': round(target_1, 2),
        'target_2': round(target_2, 2),
        'target_3': round(target_3, 2),
        'suggested_stop': round(suggested_stop, 2),
        'bb_upper': round(bb_upper, 2),
        'bb_middle': round(bb_middle, 2),
        'bb_lower': round(bb_lower, 2)
    }


def create_context_from_data(
    data: pd.DataFrame,
    ticker: str = "UNKNOWN",
    performance_report: Optional[Any] = None,
    mc_result: Optional[Any] = None,
    position_sizer: Optional[Any] = None
) -> AnalysisContext:
    """
    Create AnalysisContext from DataFrame.

    Args:
        data: DataFrame with indicators and regime data
        ticker: Stock ticker symbol
        performance_report: Optional PerformanceReport
        mc_result: Optional MonteCarloResult
        position_sizer: Optional PositionSizer for Kelly/GARCH metrics

    Returns:
        AnalysisContext object
    """
    latest = data.iloc[-1]

    context = AnalysisContext(
        ticker=ticker,
        current_price=float(latest['Close']),
        current_date=str(data.index[-1].date()) if hasattr(data.index[-1], 'date') else str(data.index[-1]),

        # Technical indicators
        rsi=float(latest.get('RSI', 50)),
        macd=float(latest.get('MACD', 0)),
        macd_signal=float(latest.get('MACD_Signal', 0)),
        sma_50=float(latest.get('SMA_50', latest['Close'])),
        sma_200=float(latest.get('SMA_200', latest['Close'])),
        bb_percent_b=float(latest.get('BB_Percent_B', 0.5)),
        atr=float(latest.get('ATR', 0)),
        adx=float(latest.get('ADX', 25)),

        # Regime
        market_regime=str(latest.get('Market_Regime', 'SIDEWAYS')),
        volatility_regime=str(latest.get('Volatility_Regime', 'NORMAL_VOLATILITY')),
        trend_persistence=str(latest.get('Trend_Persistence', 'RANDOM_WALK')),
        hurst_exponent=float(latest.get('Hurst_Exponent', 0.5)),
        regime_confidence=float(latest.get('Regime_Confidence', 0.5)),

        # Signal
        signal=str(latest.get('Signal', 'HOLD')),
        signal_confidence=float(latest.get('Signal_Confidence', 0.5)),
        confluence_score=float(latest.get('Confluence_Score', 0)),
        strategy=str(latest.get('Strategy', 'TREND_FOLLOWING'))
    )

    # Add comprehensive performance metrics if available
    if performance_report:
        # Basic metrics
        context.total_return = getattr(performance_report, 'total_return', None)
        context.cagr = getattr(performance_report, 'cagr', None)
        context.volatility = getattr(performance_report, 'volatility', None)
        context.sharpe_ratio = getattr(performance_report, 'sharpe_ratio', None)
        context.max_drawdown = getattr(performance_report, 'max_drawdown', None)

        # Advanced risk-adjusted metrics
        context.sortino_ratio = getattr(performance_report, 'sortino_ratio', None)
        context.calmar_ratio = getattr(performance_report, 'calmar_ratio', None)
        context.omega_ratio = getattr(performance_report, 'omega_ratio', None)
        context.profit_factor = getattr(performance_report, 'profit_factor', None)

        # Risk metrics (VaR/CVaR)
        context.var_95 = getattr(performance_report, 'var_95', None)
        context.var_99 = getattr(performance_report, 'var_99', None)
        context.cvar_95 = getattr(performance_report, 'cvar_95', None)
        context.cvar_975 = getattr(performance_report, 'cvar_975', None)

        # Probabilistic metrics
        context.probabilistic_sharpe = getattr(performance_report, 'probabilistic_sharpe', None)
        context.deflated_sharpe = getattr(performance_report, 'deflated_sharpe', None)
        sharpe_ci = getattr(performance_report, 'sharpe_confidence_interval', None)
        if sharpe_ci:
            context.sharpe_ci_lower = sharpe_ci[0]
            context.sharpe_ci_upper = sharpe_ci[1]

        # Trade statistics
        context.total_trades = getattr(performance_report, 'total_trades', None)
        context.win_rate = getattr(performance_report, 'win_rate', None)
        context.avg_win = getattr(performance_report, 'avg_win', None)
        context.avg_loss = getattr(performance_report, 'avg_loss', None)
        context.best_trade = getattr(performance_report, 'best_trade', None)
        context.worst_trade = getattr(performance_report, 'worst_trade', None)
        context.avg_trade_duration = getattr(performance_report, 'avg_trade_duration', None)

        # Statistical tests
        context.cagr_tstat = getattr(performance_report, 'cagr_tstat', None)
        context.cagr_pvalue = getattr(performance_report, 'cagr_pvalue', None)
        context.returns_skewness = getattr(performance_report, 'returns_skewness', None)
        context.returns_kurtosis = getattr(performance_report, 'returns_kurtosis', None)
        context.jarque_bera_stat = getattr(performance_report, 'jarque_bera_stat', None)
        context.jarque_bera_pvalue = getattr(performance_report, 'jarque_bera_pvalue', None)

        # Time period
        context.start_date = getattr(performance_report, 'start_date', None)
        context.end_date = getattr(performance_report, 'end_date', None)
        context.trading_days = getattr(performance_report, 'trading_days', None)
        context.years = getattr(performance_report, 'years', None)

    # Add comprehensive Monte Carlo results if available
    if mc_result:
        context.mc_cagr_percentile = getattr(mc_result, 'cagr_percentile', None)
        context.mc_is_significant = getattr(mc_result, 'is_statistically_significant', None)
        context.mc_prob_loss = getattr(mc_result, 'prob_loss_10pct', None)

        # CAGR distribution percentiles
        cagr_dist = getattr(mc_result, 'cagr_distribution', None)
        if cagr_dist is not None and hasattr(cagr_dist, '__len__') and len(cagr_dist) > 0:
            import numpy as np
            context.mc_cagr_5th = float(np.percentile(cagr_dist, 5))
            context.mc_cagr_25th = float(np.percentile(cagr_dist, 25))
            context.mc_cagr_50th = float(np.percentile(cagr_dist, 50))
            context.mc_cagr_75th = float(np.percentile(cagr_dist, 75))
            context.mc_cagr_95th = float(np.percentile(cagr_dist, 95))

        # Other MC metrics
        sharpe_dist = getattr(mc_result, 'sharpe_distribution', None)
        if sharpe_dist is not None and hasattr(sharpe_dist, '__len__') and len(sharpe_dist) > 0:
            import numpy as np
            context.mc_sharpe_median = float(np.median(sharpe_dist))

        # Note: MonteCarloResult uses 'max_dd_distribution' not 'max_drawdown_distribution'
        max_dd_dist = getattr(mc_result, 'max_dd_distribution', None)
        if max_dd_dist is not None and hasattr(max_dd_dist, '__len__') and len(max_dd_dist) > 0:
            import numpy as np
            context.mc_max_dd_median = float(np.median(max_dd_dist))

    # Add position sizing metrics if position_sizer provided
    if position_sizer is not None:
        # Get Kelly multiplier from the position sizer config (e.g., 0.25 for quarter-Kelly)
        context.kelly_multiplier = getattr(position_sizer, 'kelly_fraction', None)

        # Calculate actual Kelly fraction from trade stats if available
        if context.win_rate is not None and context.avg_win is not None and context.avg_loss is not None:
            try:
                # Kelly formula: f* = (p * b - q) / b
                # where p = win_rate, q = 1-p, b = payoff_ratio (avg_win / abs(avg_loss))
                p = context.win_rate
                q = 1 - p
                avg_loss_abs = abs(context.avg_loss) if context.avg_loss else 0.01
                b = context.avg_win / avg_loss_abs if avg_loss_abs > 0 else 1.0

                full_kelly = (p * b - q) / b if b > 0 else 0.0
                context.full_kelly = max(0.0, full_kelly)  # Kelly can't be negative (means no edge)

                # Fractional Kelly = full_kelly Ã— multiplier
                if context.kelly_multiplier:
                    context.fractional_kelly = context.full_kelly * context.kelly_multiplier
            except:
                pass

        # Get GARCH volatility forecast if model is fitted (PositionSizer uses garch_omega to indicate fitted)
        if hasattr(position_sizer, 'garch_omega') and position_sizer.garch_omega is not None:
            try:
                returns = data['Close'].pct_change().dropna()
                garch_vol = position_sizer.forecast_volatility(returns)
                context.garch_volatility = garch_vol.get('annualized_volatility', None)
                context.vol_adjusted_size = position_sizer.target_volatility / garch_vol.get('annualized_volatility', 1.0) if garch_vol.get('annualized_volatility') else None
            except:
                pass

    # === ADD COMPONENT SCORES ===
    try:
        scores = calculate_component_scores(data)
        context.momentum_score = scores['momentum_score']
        context.trend_score = scores['trend_score']
        context.volatility_score = scores['volatility_score']
        context.volume_score = scores['volume_score']
        context.overall_score = scores['overall_score']
    except Exception as e:
        pass  # Scores remain None if calculation fails

    # === ADD PRICE TARGETS AND BB LEVELS ===
    try:
        targets = calculate_price_targets(data)
        context.target_1 = targets['target_1']
        context.target_2 = targets['target_2']
        context.target_3 = targets['target_3']
        context.bb_upper = targets['bb_upper']
        context.bb_middle = targets['bb_middle']
        context.bb_lower = targets['bb_lower']
    except Exception as e:
        pass  # Targets remain None if calculation fails

    # === ADD VOLUME RATIO ===
    try:
        volume = float(latest.get('Volume', 0))
        volume_ma = float(latest.get('Volume_MA', volume)) if latest.get('Volume_MA') else volume
        if volume_ma > 0:
            context.volume_ratio = round(volume / volume_ma, 2)
    except:
        pass

    return context


# =============================================================================
# TEST SCRIPT
# =============================================================================

if __name__ == "__main__":
    import sys
    sys.path.insert(0, '.')

    from data_collector import DataCollector
    from technical_indicators import TechnicalIndicators
    from regime_detector import RegimeDetector
    from signal_generator import SignalGenerator
    from backtest_engine import BacktestEngine, BacktestConfig
    from performance_metrics import PerformanceAnalyser
    from monte_carlo import MonteCarloSimulator

    # Get ticker from command line or default to AAPL
    TICKER = sys.argv[1].upper() if len(sys.argv) > 1 else "AAPL"

    print("=" * 70)
    print(f"LLM AGENT TEST - {TICKER}")
    print("=" * 70)

    # Load and process data
    print("\nLoading data...")
    collector = DataCollector()
    data = collector.get_data(TICKER, years=10)

    print("Processing indicators...")
    ti = TechnicalIndicators(data)
    data = ti.calculate_all()

    print("Detecting regimes...")
    rd = RegimeDetector(data)
    data = rd.detect_all_regimes()

    print("Generating signals...")
    sg = SignalGenerator(data)
    data = sg.generate_signals()

    # Run backtest
    print("Running backtest...")
    config = BacktestConfig()  # Uses PositionSizer by default
    engine = BacktestEngine(data, config)
    results = engine.run_backtest()

    # Get performance metrics
    returns = engine.portfolio.returns()
    try:
        trades_df = engine.portfolio.trades.records_readable
    except:
        trades_df = None

    analyser = PerformanceAnalyser(returns, trades_df)
    report = analyser.generate_report()

    # Run Monte Carlo
    print("Running Monte Carlo...")
    simulator = MonteCarloSimulator(returns)
    mc_result = simulator.run_simulation(n_simulations=500, verbose=False)

    # Create context (pass position_sizer for Kelly/GARCH metrics)
    print("\nCreating analysis context...")
    context = create_context_from_data(
        data,
        ticker=TICKER,
        performance_report=report,
        mc_result=mc_result,
        position_sizer=engine.position_sizer
    )

    print(f"\nContext created:")
    print(f"  Price: ${context.current_price:.2f}")
    print(f"  RSI: {context.rsi:.1f}")
    print(f"  Regime: {context.market_regime}")
    print(f"  Signal: {context.signal}")

    # Initialise LLM agent
    print("\n" + "=" * 70)
    print("INITIALISING LLM AGENT")
    print("=" * 70)

    agent = LLMAgent(data)
    agent.trades_df = trades_df

    # Check if API is available
    if agent.anthropic_client is None and agent.openai_client is None:
        print("\nNo API keys configured. Showing placeholder output...")
        print("\nTo enable LLM analysis, set environment variables:")
        print("  export ANTHROPIC_API_KEY=your_key")
        print("  or")
        print("  export OPENAI_API_KEY=your_key")
    else:
        # Generate recommendation
        print("\n" + "=" * 70)
        print("GENERATING TRADE RECOMMENDATION")
        print("=" * 70)

        recommendation = agent.generate_trade_recommendation(context)

        print(f"\nRecommendation: {recommendation.recommendation.value}")
        print(f"Confidence: {recommendation.confidence:.0%}")
        print(f"Entry: ${recommendation.entry_price:.2f}")
        print(f"Stop: ${recommendation.stop_loss:.2f}")
        print(f"Target: ${recommendation.take_profit:.2f}")
        print(f"R:R: 1:{recommendation.risk_reward_ratio:.1f}")
        print(f"\nRationale: {recommendation.rationale[:200]}...")

        print(f"\nRisks:")
        for risk in recommendation.risks[:3]:
            print(f"  - {risk}")

        # Reuse the recommendation for all outputs (single API call already made above)
        print("\n" + "=" * 70)
        print("GENERATING JSON REPORT (reusing recommendation - no extra API call)")
        print("=" * 70)

        json_output = agent.generate_json_report(context, recommendation=recommendation)
        print("\nJSON Output Structure:")
        print(f"  - metadata: ticker, date, price, model")
        print(f"  - recommendation: {json_output['recommendation']['action']} ({json_output['recommendation']['confidence']:.0%})")
        print(f"  - trade_specifications: entry, stop, target, R:R")
        print(f"  - technical_analysis: momentum, trend, volatility")
        print(f"  - regime_analysis: {json_output['regime_analysis']['market_regime']}")
        print(f"  - signal_system: {json_output['signal_system']['current_signal']}")
        print(f"  - risk_factors: {len(json_output['risk_factors'])} items")
        print(f"  - catalysts: {len(json_output['catalysts'])} items")
        if 'performance_analysis' in json_output:
            print(f"  - performance_analysis: {json_output['performance_analysis'].get('overall_assessment', 'N/A')}")
        if 'backtest_metrics' in json_output:
            print(f"  - backtest_metrics: CAGR={json_output['backtest_metrics']['return_metrics']['cagr']:.1%}, Sharpe={json_output['backtest_metrics']['risk_adjusted_metrics']['sharpe_ratio']:.2f}")
        if 'monte_carlo' in json_output:
            print(f"  - monte_carlo: {json_output['monte_carlo']['statistical_significance']['cagr_percentile']:.0f}th percentile")

        # Show full JSON string
        print("\n" + "-" * 70)
        print("FULL JSON OUTPUT:")
        print("-" * 70)
        json_string = json.dumps(json_output, indent=2, default=str)  # Reuse json_output
        print(json_string)

        # Also show text report for comparison
        print("\n" + "=" * 70)
        print("TEXT REPORT (reusing recommendation - no extra API call)")
        print("=" * 70)

        full_report = agent.generate_full_report(context, recommendation=recommendation)
        print(full_report)

        # Save all outputs to files (internally reuses recommendation)
        print("\n" + "=" * 70)
        print("SAVING OUTPUTS TO FILES")
        print("=" * 70)

        # Save directly using already-generated data (no additional API calls)
        output_dir = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))),
            "shared_outputs"
        )
        os.makedirs(output_dir, exist_ok=True)
        base_filename = f"technical_fardeen_{context.ticker}"

        json_path = os.path.join(output_dir, f"{base_filename}.json")
        agent._save_json(json_output, json_path)
        print(f"\nJSON saved: {json_path}")

    print("\n" + "=" * 70)
    print("LLM AGENT TEST COMPLETE")
    print("=" * 70)